

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>tensorflow.python.ops.distributions.util &mdash; zfit 0.2.3 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../../../../../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../../../" src="../../../../../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../../../../../_static/jquery.js"></script>
        <script type="text/javascript" src="../../../../../_static/underscore.js"></script>
        <script type="text/javascript" src="../../../../../_static/doctools.js"></script>
        <script type="text/javascript" src="../../../../../_static/language_data.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../../../../../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../../../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../../../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../../../index.html" class="icon icon-home"> zfit
          

          
          </a>

          
            
            
              <div class="version">
                0.2.3
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../readme.html">zfit</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../zfit.pdf.html">zfit.pdf</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../zfit.func.html">zfit.func</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../zfit.data.html">zfit.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../zfit.minimize.html">zfit.minimize</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../zfit.loss.html">zfit.loss</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../zfit.constraint.html">zfit.constraint</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../zfit.ztf.html">zfit.ztf</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../usage.html">Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../contributing.html">Contributing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../authors.html">Credits</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../history.html">History</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../../index.html">zfit</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../../../../index.html">Module code</a> &raquo;</li>
        
      <li>tensorflow.python.ops.distributions.util</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for tensorflow.python.ops.distributions.util</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright 2016 The TensorFlow Authors. All Rights Reserved.</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="c1"># ==============================================================================</span>
<span class="sd">&quot;&quot;&quot;Utilities for probability distributions.&quot;&quot;&quot;</span>

<span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">absolute_import</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">division</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">print_function</span>

<span class="kn">import</span> <span class="nn">functools</span>
<span class="kn">import</span> <span class="nn">hashlib</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">tensorflow.python.framework</span> <span class="k">import</span> <span class="n">constant_op</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.framework</span> <span class="k">import</span> <span class="n">dtypes</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.framework</span> <span class="k">import</span> <span class="n">ops</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.framework</span> <span class="k">import</span> <span class="n">tensor_shape</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.framework</span> <span class="k">import</span> <span class="n">tensor_util</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.ops</span> <span class="k">import</span> <span class="n">array_ops</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.ops</span> <span class="k">import</span> <span class="n">check_ops</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.ops</span> <span class="k">import</span> <span class="n">control_flow_ops</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.ops</span> <span class="k">import</span> <span class="n">linalg_ops</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.ops</span> <span class="k">import</span> <span class="n">math_ops</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.ops</span> <span class="k">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.util</span> <span class="k">import</span> <span class="n">tf_inspect</span>


<span class="k">def</span> <span class="nf">assert_integer_form</span><span class="p">(</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">summarize</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">int_dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;assert_integer_form&quot;</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Assert that x has integer components (or floats equal to integers).</span>

<span class="sd">  Args:</span>
<span class="sd">    x: Floating-point `Tensor`</span>
<span class="sd">    data: The tensors to print out if the condition is `False`. Defaults to</span>
<span class="sd">      error message and first few entries of `x` and `y`.</span>
<span class="sd">    summarize: Print this many entries of each tensor.</span>
<span class="sd">    message: A string to prefix to the default message.</span>
<span class="sd">    int_dtype: A `tf.dtype` used to cast the float to. The default (`None`)</span>
<span class="sd">      implies the smallest possible signed int will be used for casting.</span>
<span class="sd">    name: A name for this operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    Op raising `InvalidArgumentError` if `cast(x, int_dtype) != x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">with</span> <span class="n">ops</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">data</span><span class="p">]):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;x&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">is_integer</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">control_flow_ops</span><span class="o">.</span><span class="n">no_op</span><span class="p">()</span>
    <span class="n">message</span> <span class="o">=</span> <span class="n">message</span> <span class="ow">or</span> <span class="s2">&quot;</span><span class="si">{}</span><span class="s2"> has non-integer components&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">int_dtype</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="n">int_dtype</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">dtypes</span><span class="o">.</span><span class="n">float16</span><span class="p">:</span> <span class="n">dtypes</span><span class="o">.</span><span class="n">int16</span><span class="p">,</span>
            <span class="n">dtypes</span><span class="o">.</span><span class="n">float32</span><span class="p">:</span> <span class="n">dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span>
            <span class="n">dtypes</span><span class="o">.</span><span class="n">float64</span><span class="p">:</span> <span class="n">dtypes</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span>
        <span class="p">}[</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">base_dtype</span><span class="p">]</span>
      <span class="k">except</span> <span class="ne">KeyError</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Unrecognized type </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">name</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">check_ops</span><span class="o">.</span><span class="n">assert_equal</span><span class="p">(</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">math_ops</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">math_ops</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">int_dtype</span><span class="p">),</span> <span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span>
        <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">summarize</span><span class="o">=</span><span class="n">summarize</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="n">message</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">assert_symmetric</span><span class="p">(</span><span class="n">matrix</span><span class="p">):</span>
  <span class="n">matrix_t</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">matrix_transpose</span><span class="p">(</span><span class="n">matrix</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">control_flow_ops</span><span class="o">.</span><span class="n">with_dependencies</span><span class="p">(</span>
      <span class="p">[</span><span class="n">check_ops</span><span class="o">.</span><span class="n">assert_equal</span><span class="p">(</span><span class="n">matrix</span><span class="p">,</span> <span class="n">matrix_t</span><span class="p">)],</span> <span class="n">matrix</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">embed_check_nonnegative_integer_form</span><span class="p">(</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;embed_check_nonnegative_integer_form&quot;</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Assert x is a non-negative tensor, and optionally of integers.&quot;&quot;&quot;</span>
  <span class="k">with</span> <span class="n">ops</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="p">[</span><span class="n">x</span><span class="p">]):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;x&quot;</span><span class="p">)</span>
    <span class="n">assertions</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">check_ops</span><span class="o">.</span><span class="n">assert_non_negative</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="s2">&quot;&#39;</span><span class="si">{}</span><span class="s2">&#39; must be non-negative.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">x</span><span class="p">)),</span>
    <span class="p">]</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">is_integer</span><span class="p">:</span>
      <span class="n">assertions</span> <span class="o">+=</span> <span class="p">[</span>
          <span class="n">assert_integer_form</span><span class="p">(</span>
              <span class="n">x</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="s2">&quot;&#39;</span><span class="si">{}</span><span class="s2">&#39; cannot contain fractional components.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                  <span class="n">x</span><span class="p">)),</span>
      <span class="p">]</span>
    <span class="k">return</span> <span class="n">control_flow_ops</span><span class="o">.</span><span class="n">with_dependencies</span><span class="p">(</span><span class="n">assertions</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">same_dynamic_shape</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Returns whether a and b have the same dynamic shape.</span>

<span class="sd">  Args:</span>
<span class="sd">    a: `Tensor`</span>
<span class="sd">    b: `Tensor`</span>

<span class="sd">  Returns:</span>
<span class="sd">    `bool` `Tensor` representing if both tensors have the same shape.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">a</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;a&quot;</span><span class="p">)</span>
  <span class="n">b</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;b&quot;</span><span class="p">)</span>

  <span class="c1"># Here we can&#39;t just do math_ops.equal(a.shape, b.shape), since</span>
  <span class="c1"># static shape inference may break the equality comparison between</span>
  <span class="c1"># shape(a) and shape(b) in math_ops.equal.</span>
  <span class="k">def</span> <span class="nf">all_shapes_equal</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">math_ops</span><span class="o">.</span><span class="n">reduce_all</span><span class="p">(</span><span class="n">math_ops</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span>
        <span class="n">array_ops</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">array_ops</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">a</span><span class="p">),</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">b</span><span class="p">)],</span> <span class="mi">0</span><span class="p">),</span>
        <span class="n">array_ops</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">array_ops</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">b</span><span class="p">),</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">a</span><span class="p">)],</span> <span class="mi">0</span><span class="p">)))</span>

  <span class="c1"># One of the shapes isn&#39;t fully defined, so we need to use the dynamic</span>
  <span class="c1"># shape.</span>
  <span class="k">return</span> <span class="n">control_flow_ops</span><span class="o">.</span><span class="n">cond</span><span class="p">(</span>
      <span class="n">math_ops</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">array_ops</span><span class="o">.</span><span class="n">rank</span><span class="p">(</span><span class="n">a</span><span class="p">),</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">rank</span><span class="p">(</span><span class="n">b</span><span class="p">)),</span>
      <span class="n">all_shapes_equal</span><span class="p">,</span>
      <span class="k">lambda</span><span class="p">:</span> <span class="n">constant_op</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="kc">False</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">maybe_get_static_value</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Helper which tries to return a static value.</span>

<span class="sd">  Given `x`, extract it&#39;s value statically, optionally casting to a specific</span>
<span class="sd">  dtype. If this is not possible, None is returned.</span>

<span class="sd">  Args:</span>
<span class="sd">    x: `Tensor` for which to extract a value statically.</span>
<span class="sd">    dtype: Optional dtype to cast to.</span>

<span class="sd">  Returns:</span>
<span class="sd">    Statically inferred value if possible, otherwise None.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="n">x</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">x</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="c1"># This returns an np.ndarray.</span>
    <span class="n">x_</span> <span class="o">=</span> <span class="n">tensor_util</span><span class="o">.</span><span class="n">constant_value</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
  <span class="k">except</span> <span class="ne">TypeError</span><span class="p">:</span>
    <span class="n">x_</span> <span class="o">=</span> <span class="n">x</span>
  <span class="k">if</span> <span class="n">x_</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">x_</span>
  <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x_</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">get_logits_and_probs</span><span class="p">(</span><span class="n">logits</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                         <span class="n">probs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                         <span class="n">multidimensional</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                         <span class="n">validate_args</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                         <span class="n">name</span><span class="o">=</span><span class="s2">&quot;get_logits_and_probs&quot;</span><span class="p">,</span>
                         <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Converts logit to probabilities (or vice-versa), and returns both.</span>

<span class="sd">  Args:</span>
<span class="sd">    logits: Floating-point `Tensor` representing log-odds.</span>
<span class="sd">    probs: Floating-point `Tensor` representing probabilities.</span>
<span class="sd">    multidimensional: Python `bool`, default `False`.</span>
<span class="sd">      If `True`, represents whether the last dimension of `logits` or `probs`,</span>
<span class="sd">      a `[N1, N2, ...  k]` dimensional tensor, representing the</span>
<span class="sd">      logit or probability of `shape[-1]` classes.</span>
<span class="sd">    validate_args: Python `bool`, default `False`. When `True`, either assert</span>
<span class="sd">      `0 &lt;= probs &lt;= 1` (if not `multidimensional`) or that the last dimension</span>
<span class="sd">      of `probs` sums to one.</span>
<span class="sd">    name: A name for this operation (optional).</span>
<span class="sd">    dtype: `tf.DType` to prefer when converting args to `Tensor`s.</span>

<span class="sd">  Returns:</span>
<span class="sd">    logits, probs: Tuple of `Tensor`s. If `probs` has an entry that is `0` or</span>
<span class="sd">      `1`, then the corresponding entry in the returned logit will be `-Inf` and</span>
<span class="sd">      `Inf` respectively.</span>

<span class="sd">  Raises:</span>
<span class="sd">    ValueError: if neither `probs` nor `logits` were passed in, or both were.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">with</span> <span class="n">ops</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="p">[</span><span class="n">probs</span><span class="p">,</span> <span class="n">logits</span><span class="p">]):</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">probs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">)</span> <span class="o">==</span> <span class="p">(</span><span class="n">logits</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">):</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Must pass probs or logits, but not both.&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">probs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">logits</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;logits&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
      <span class="k">if</span> <span class="ow">not</span> <span class="n">logits</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">is_floating</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;logits must having floating type.&quot;</span><span class="p">)</span>
      <span class="c1"># We can early return since we constructed probs and therefore know</span>
      <span class="c1"># they&#39;re valid.</span>
      <span class="k">if</span> <span class="n">multidimensional</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">validate_args</span><span class="p">:</span>
          <span class="n">logits</span> <span class="o">=</span> <span class="n">embed_check_categorical_event_shape</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">logits</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;probs&quot;</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">logits</span><span class="p">,</span> <span class="n">math_ops</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;probs&quot;</span><span class="p">)</span>

    <span class="n">probs</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">probs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;probs&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">probs</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">is_floating</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;probs must having floating type.&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">validate_args</span><span class="p">:</span>
      <span class="k">with</span> <span class="n">ops</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s2">&quot;validate_probs&quot;</span><span class="p">):</span>
        <span class="n">one</span> <span class="o">=</span> <span class="n">constant_op</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">1.</span><span class="p">,</span> <span class="n">probs</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="n">dependencies</span> <span class="o">=</span> <span class="p">[</span><span class="n">check_ops</span><span class="o">.</span><span class="n">assert_non_negative</span><span class="p">(</span><span class="n">probs</span><span class="p">)]</span>
        <span class="k">if</span> <span class="n">multidimensional</span><span class="p">:</span>
          <span class="n">probs</span> <span class="o">=</span> <span class="n">embed_check_categorical_event_shape</span><span class="p">(</span><span class="n">probs</span><span class="p">)</span>
          <span class="n">dependencies</span> <span class="o">+=</span> <span class="p">[</span>
              <span class="n">check_ops</span><span class="o">.</span><span class="n">assert_near</span><span class="p">(</span>
                  <span class="n">math_ops</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">probs</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
                  <span class="n">one</span><span class="p">,</span>
                  <span class="n">message</span><span class="o">=</span><span class="s2">&quot;probs does not sum to 1.&quot;</span><span class="p">)</span>
          <span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
          <span class="n">dependencies</span> <span class="o">+=</span> <span class="p">[</span><span class="n">check_ops</span><span class="o">.</span><span class="n">assert_less_equal</span><span class="p">(</span>
              <span class="n">probs</span><span class="p">,</span> <span class="n">one</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="s2">&quot;probs has components greater than 1.&quot;</span><span class="p">)]</span>
        <span class="n">probs</span> <span class="o">=</span> <span class="n">control_flow_ops</span><span class="o">.</span><span class="n">with_dependencies</span><span class="p">(</span><span class="n">dependencies</span><span class="p">,</span> <span class="n">probs</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">ops</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s2">&quot;logits&quot;</span><span class="p">):</span>
      <span class="k">if</span> <span class="n">multidimensional</span><span class="p">:</span>
        <span class="c1"># Here we don&#39;t compute the multidimensional case, in a manner</span>
        <span class="c1"># consistent with respect to the unidimensional case. We do so</span>
        <span class="c1"># following the TF convention. Typically, you might expect to see</span>
        <span class="c1"># logits = log(probs) - log(probs[pivot]). A side-effect of</span>
        <span class="c1"># being consistent with the TF approach is that the unidimensional case</span>
        <span class="c1"># implicitly handles the second dimension but the multidimensional case</span>
        <span class="c1"># explicitly keeps the pivot dimension.</span>
        <span class="k">return</span> <span class="n">math_ops</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">probs</span><span class="p">),</span> <span class="n">probs</span>
      <span class="k">return</span> <span class="n">math_ops</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">probs</span><span class="p">)</span> <span class="o">-</span> <span class="n">math_ops</span><span class="o">.</span><span class="n">log1p</span><span class="p">(</span><span class="o">-</span><span class="mf">1.</span> <span class="o">*</span> <span class="n">probs</span><span class="p">),</span> <span class="n">probs</span>


<span class="k">def</span> <span class="nf">_is_known_unsigned_by_dtype</span><span class="p">(</span><span class="n">dt</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Helper returning True if dtype is known to be unsigned.&quot;&quot;&quot;</span>
  <span class="k">return</span> <span class="p">{</span>
      <span class="n">dtypes</span><span class="o">.</span><span class="n">bool</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
      <span class="n">dtypes</span><span class="o">.</span><span class="n">uint8</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
      <span class="n">dtypes</span><span class="o">.</span><span class="n">uint16</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
  <span class="p">}</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">base_dtype</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_is_known_signed_by_dtype</span><span class="p">(</span><span class="n">dt</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Helper returning True if dtype is known to be signed.&quot;&quot;&quot;</span>
  <span class="k">return</span> <span class="p">{</span>
      <span class="n">dtypes</span><span class="o">.</span><span class="n">float16</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
      <span class="n">dtypes</span><span class="o">.</span><span class="n">float32</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
      <span class="n">dtypes</span><span class="o">.</span><span class="n">float64</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
      <span class="n">dtypes</span><span class="o">.</span><span class="n">int8</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
      <span class="n">dtypes</span><span class="o">.</span><span class="n">int16</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
      <span class="n">dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
      <span class="n">dtypes</span><span class="o">.</span><span class="n">int64</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
  <span class="p">}</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">base_dtype</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_is_known_dtype</span><span class="p">(</span><span class="n">dt</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Helper returning True if dtype is known.&quot;&quot;&quot;</span>
  <span class="k">return</span> <span class="n">_is_known_unsigned_by_dtype</span><span class="p">(</span><span class="n">dt</span><span class="p">)</span> <span class="ow">or</span> <span class="n">_is_known_signed_by_dtype</span><span class="p">(</span><span class="n">dt</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_largest_integer_by_dtype</span><span class="p">(</span><span class="n">dt</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Helper returning the largest integer exactly representable by dtype.&quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="n">_is_known_dtype</span><span class="p">(</span><span class="n">dt</span><span class="p">):</span>
    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Unrecognized dtype: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">name</span><span class="p">))</span>
  <span class="k">if</span> <span class="n">dt</span><span class="o">.</span><span class="n">is_floating</span><span class="p">:</span>
    <span class="k">return</span> <span class="nb">int</span><span class="p">(</span><span class="mi">2</span><span class="o">**</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">as_numpy_dtype</span><span class="p">)</span><span class="o">.</span><span class="n">nmant</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
  <span class="k">if</span> <span class="n">dt</span><span class="o">.</span><span class="n">is_integer</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">iinfo</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">as_numpy_dtype</span><span class="p">)</span><span class="o">.</span><span class="n">max</span>
  <span class="k">if</span> <span class="n">dt</span><span class="o">.</span><span class="n">base_dtype</span> <span class="o">==</span> <span class="n">dtypes</span><span class="o">.</span><span class="n">bool</span><span class="p">:</span>
    <span class="k">return</span> <span class="nb">int</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
  <span class="c1"># We actually can&#39;t land here but keep the case for completeness.</span>
  <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Unrecognized dtype: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">name</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">_smallest_integer_by_dtype</span><span class="p">(</span><span class="n">dt</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Helper returning the smallest integer exactly representable by dtype.&quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="n">_is_known_dtype</span><span class="p">(</span><span class="n">dt</span><span class="p">):</span>
    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Unrecognized dtype: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">name</span><span class="p">))</span>
  <span class="k">if</span> <span class="n">_is_known_unsigned_by_dtype</span><span class="p">(</span><span class="n">dt</span><span class="p">):</span>
    <span class="k">return</span> <span class="mi">0</span>
  <span class="k">return</span> <span class="o">-</span><span class="mi">1</span> <span class="o">*</span> <span class="n">_largest_integer_by_dtype</span><span class="p">(</span><span class="n">dt</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_is_integer_like_by_dtype</span><span class="p">(</span><span class="n">dt</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Helper returning True if dtype.is_integer or is `bool`.&quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="n">_is_known_dtype</span><span class="p">(</span><span class="n">dt</span><span class="p">):</span>
    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Unrecognized dtype: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">name</span><span class="p">))</span>
  <span class="k">return</span> <span class="n">dt</span><span class="o">.</span><span class="n">is_integer</span> <span class="ow">or</span> <span class="n">dt</span><span class="o">.</span><span class="n">base_dtype</span> <span class="o">==</span> <span class="n">dtypes</span><span class="o">.</span><span class="n">bool</span>


<span class="k">def</span> <span class="nf">embed_check_categorical_event_shape</span><span class="p">(</span>
    <span class="n">categorical_param</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;embed_check_categorical_event_shape&quot;</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Embeds checks that categorical distributions don&#39;t have too many classes.</span>

<span class="sd">  A categorical-type distribution is one which, e.g., returns the class label</span>
<span class="sd">  rather than a one-hot encoding.  E.g., `Categorical(probs)`.</span>

<span class="sd">  Since distributions output samples in the same dtype as the parameters, we</span>
<span class="sd">  must ensure that casting doesn&#39;t lose precision. That is, the</span>
<span class="sd">  `parameter.dtype` implies a maximum number of classes. However, since shape is</span>
<span class="sd">  `int32` and categorical variables are presumed to be indexes into a `Tensor`,</span>
<span class="sd">  we must also ensure that the number of classes is no larger than the largest</span>
<span class="sd">  possible `int32` index, i.e., `2**31-1`.</span>

<span class="sd">  In other words the number of classes, `K`, must satisfy the following</span>
<span class="sd">  condition:</span>

<span class="sd">  ```python</span>
<span class="sd">  K &lt;= min(</span>
<span class="sd">      int(2**31 - 1),  # Largest float as an index.</span>
<span class="sd">      {</span>
<span class="sd">          dtypes.float16: int(2**11),   # Largest int as a float16.</span>
<span class="sd">          dtypes.float32: int(2**24),</span>
<span class="sd">          dtypes.float64: int(2**53),</span>
<span class="sd">      }.get(categorical_param.dtype.base_dtype, 0))</span>
<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    categorical_param: Floating-point `Tensor` representing parameters of</span>
<span class="sd">      distribution over categories. The rightmost shape is presumed to be the</span>
<span class="sd">      number of categories.</span>
<span class="sd">    name: A name for this operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    categorical_param: Input `Tensor` with appropriate assertions embedded.</span>

<span class="sd">  Raises:</span>
<span class="sd">    TypeError: if `categorical_param` has an unknown `dtype`.</span>
<span class="sd">    ValueError: if we can statically identify `categorical_param` as being too</span>
<span class="sd">      large (for being closed under int32/float casting).</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">with</span> <span class="n">ops</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="p">[</span><span class="n">categorical_param</span><span class="p">]):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">categorical_param</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;categorical_param&quot;</span><span class="p">)</span>
    <span class="c1"># The size must not exceed both of:</span>
    <span class="c1"># - The largest possible int32 (since categorical values are presumed to be</span>
    <span class="c1">#   indexes into a Tensor).</span>
    <span class="c1"># - The largest possible integer exactly representable under the given</span>
    <span class="c1">#   floating-point dtype (since we need to cast to/from).</span>
    <span class="c1">#</span>
    <span class="c1"># The chosen floating-point thresholds are 2**(1 + mantissa_bits).</span>
    <span class="c1"># For more details, see:</span>
    <span class="c1"># https://en.wikipedia.org/wiki/Floating-point_arithmetic#Internal_representation</span>
    <span class="n">x_dtype</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">base_dtype</span>
    <span class="n">max_event_size</span> <span class="o">=</span> <span class="p">(</span><span class="n">_largest_integer_by_dtype</span><span class="p">(</span><span class="n">x_dtype</span><span class="p">)</span>
                      <span class="k">if</span> <span class="n">x_dtype</span><span class="o">.</span><span class="n">is_floating</span> <span class="k">else</span> <span class="mi">0</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">max_event_size</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Unable to validate size of unrecognized dtype &quot;</span>
                      <span class="s2">&quot;(</span><span class="si">{}</span><span class="s2">).&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">x_dtype</span><span class="o">.</span><span class="n">name</span><span class="p">))</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">x_shape_static</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span><span class="o">.</span><span class="n">with_rank_at_least</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;A categorical-distribution parameter must have &quot;</span>
                       <span class="s2">&quot;at least 1 dimension.&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">tensor_shape</span><span class="o">.</span><span class="n">dimension_value</span><span class="p">(</span><span class="n">x_shape_static</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">event_size</span> <span class="o">=</span> <span class="n">x_shape_static</span><span class="o">.</span><span class="n">dims</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">value</span>
      <span class="k">if</span> <span class="n">event_size</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;A categorical-distribution parameter must have at &quot;</span>
                         <span class="s2">&quot;least 2 events.&quot;</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">event_size</span> <span class="o">&gt;</span> <span class="n">max_event_size</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;Number of classes exceeds `dtype` precision, i.e., &quot;</span>
            <span class="s2">&quot;</span><span class="si">{}</span><span class="s2"> implies shape (</span><span class="si">{}</span><span class="s2">) cannot exceed </span><span class="si">{}</span><span class="s2">.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="n">x_dtype</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">event_size</span><span class="p">,</span> <span class="n">max_event_size</span><span class="p">))</span>
      <span class="k">return</span> <span class="n">x</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">event_size</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;x_shape&quot;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
      <span class="k">return</span> <span class="n">control_flow_ops</span><span class="o">.</span><span class="n">with_dependencies</span><span class="p">([</span>
          <span class="n">check_ops</span><span class="o">.</span><span class="n">assert_rank_at_least</span><span class="p">(</span>
              <span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;A categorical-distribution parameter must have &quot;</span>
                             <span class="s2">&quot;at least 1 dimension.&quot;</span><span class="p">)),</span>
          <span class="n">check_ops</span><span class="o">.</span><span class="n">assert_greater_equal</span><span class="p">(</span>
              <span class="n">array_ops</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="mi">2</span><span class="p">,</span>
              <span class="n">message</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;A categorical-distribution parameter must have at &quot;</span>
                       <span class="s2">&quot;least 2 events.&quot;</span><span class="p">)),</span>
          <span class="n">check_ops</span><span class="o">.</span><span class="n">assert_less_equal</span><span class="p">(</span>
              <span class="n">event_size</span><span class="p">,</span> <span class="n">max_event_size</span><span class="p">,</span>
              <span class="n">message</span><span class="o">=</span><span class="s2">&quot;Number of classes exceeds `dtype` precision, &quot;</span>
                      <span class="s2">&quot;i.e., </span><span class="si">{}</span><span class="s2"> dtype cannot exceed </span><span class="si">{}</span><span class="s2"> shape.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                          <span class="n">x_dtype</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">max_event_size</span><span class="p">)),</span>
      <span class="p">],</span> <span class="n">x</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">embed_check_integer_casting_closed</span><span class="p">(</span>
    <span class="n">x</span><span class="p">,</span>
    <span class="n">target_dtype</span><span class="p">,</span>
    <span class="n">assert_nonnegative</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;embed_check_casting_closed&quot;</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Ensures integers remain unaffected despite casting to/from int/float types.</span>

<span class="sd">  Example integer-types: `uint8`, `int32`, `bool`.</span>
<span class="sd">  Example floating-types: `float32`, `float64`.</span>

<span class="sd">  The largest possible integer representable by an IEEE754 floating-point is</span>
<span class="sd">  `2**(1 + mantissa_bits)` yet the largest possible integer as an int-type is</span>
<span class="sd">  `2**(bits - 1) - 1`. This function ensures that a `Tensor` purporting to have</span>
<span class="sd">  integer-form values can be cast to some other type without loss of precision.</span>

<span class="sd">  The smallest representable integer is the negative of the largest</span>
<span class="sd">  representable integer, except for types: `uint8`, `uint16`, `bool`. For these</span>
<span class="sd">  types, the smallest representable integer is `0`.</span>

<span class="sd">  Args:</span>
<span class="sd">    x: `Tensor` representing integer-form values.</span>
<span class="sd">    target_dtype: TF `dtype` under which `x` should have identical values.</span>
<span class="sd">    assert_nonnegative: `bool` indicating `x` should contain nonnegative values.</span>
<span class="sd">    name: A name for this operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    x: Input `Tensor` with appropriate assertions embedded.</span>

<span class="sd">  Raises:</span>
<span class="sd">    TypeError: if `x` is neither integer- nor floating-type.</span>
<span class="sd">    TypeError: if `target_dtype` is neither integer- nor floating-type.</span>
<span class="sd">    TypeError: if neither `x` nor `target_dtype` are integer-type.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">with</span> <span class="n">ops</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="p">[</span><span class="n">x</span><span class="p">]):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;x&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="p">(</span><span class="ow">not</span> <span class="n">_is_integer_like_by_dtype</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="ow">and</span> <span class="ow">not</span> <span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">is_floating</span><span class="p">):</span>
      <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{}</span><span class="s2">.dtype must be floating- or &quot;</span>
                      <span class="s2">&quot;integer-type.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">name</span><span class="p">))</span>
    <span class="k">if</span> <span class="p">(</span><span class="ow">not</span> <span class="n">_is_integer_like_by_dtype</span><span class="p">(</span><span class="n">target_dtype</span><span class="p">)</span>
        <span class="ow">and</span> <span class="ow">not</span> <span class="n">target_dtype</span><span class="o">.</span><span class="n">is_floating</span><span class="p">):</span>
      <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;target_dtype (</span><span class="si">{}</span><span class="s2">) must be floating- or &quot;</span>
                      <span class="s2">&quot;integer-type.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">target_dtype</span><span class="o">.</span><span class="n">name</span><span class="p">))</span>
    <span class="k">if</span> <span class="p">(</span><span class="ow">not</span> <span class="n">_is_integer_like_by_dtype</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="ow">and</span> <span class="ow">not</span> <span class="n">_is_integer_like_by_dtype</span><span class="p">(</span><span class="n">target_dtype</span><span class="p">)):</span>
      <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;At least one of </span><span class="si">{}</span><span class="s2">.dtype (</span><span class="si">{}</span><span class="s2">) and target_dtype (</span><span class="si">{}</span><span class="s2">) &quot;</span>
                      <span class="s2">&quot;must be integer-type.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                          <span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">target_dtype</span><span class="o">.</span><span class="n">name</span><span class="p">))</span>

    <span class="n">assertions</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">if</span> <span class="n">assert_nonnegative</span><span class="p">:</span>
      <span class="n">assertions</span> <span class="o">+=</span> <span class="p">[</span>
          <span class="n">check_ops</span><span class="o">.</span><span class="n">assert_non_negative</span><span class="p">(</span>
              <span class="n">x</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="s2">&quot;Elements must be non-negative.&quot;</span><span class="p">),</span>
      <span class="p">]</span>

    <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">is_floating</span><span class="p">:</span>
      <span class="c1"># Being here means _is_integer_like_by_dtype(target_dtype) = True.</span>
      <span class="c1"># Since this check implies the magnitude check below, we need only it.</span>
      <span class="n">assertions</span> <span class="o">+=</span> <span class="p">[</span>
          <span class="n">assert_integer_form</span><span class="p">(</span>
              <span class="n">x</span><span class="p">,</span> <span class="n">int_dtype</span><span class="o">=</span><span class="n">target_dtype</span><span class="p">,</span>
              <span class="n">message</span><span class="o">=</span><span class="s2">&quot;Elements must be </span><span class="si">{}</span><span class="s2">-equivalent.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                  <span class="n">target_dtype</span><span class="o">.</span><span class="n">name</span><span class="p">)),</span>
      <span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">if</span> <span class="p">(</span><span class="n">_largest_integer_by_dtype</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
          <span class="o">&gt;</span> <span class="n">_largest_integer_by_dtype</span><span class="p">(</span><span class="n">target_dtype</span><span class="p">)):</span>
        <span class="c1"># Cast may lose integer precision.</span>
        <span class="n">assertions</span> <span class="o">+=</span> <span class="p">[</span>
            <span class="n">check_ops</span><span class="o">.</span><span class="n">assert_less_equal</span><span class="p">(</span>
                <span class="n">x</span><span class="p">,</span> <span class="n">_largest_integer_by_dtype</span><span class="p">(</span><span class="n">target_dtype</span><span class="p">),</span>
                <span class="n">message</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;Elements cannot exceed </span><span class="si">{}</span><span class="s2">.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="n">_largest_integer_by_dtype</span><span class="p">(</span><span class="n">target_dtype</span><span class="p">)))),</span>
        <span class="p">]</span>
      <span class="k">if</span> <span class="p">(</span><span class="ow">not</span> <span class="n">assert_nonnegative</span> <span class="ow">and</span>
          <span class="p">(</span><span class="n">_smallest_integer_by_dtype</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
           <span class="o">&lt;</span> <span class="n">_smallest_integer_by_dtype</span><span class="p">(</span><span class="n">target_dtype</span><span class="p">))):</span>
        <span class="n">assertions</span> <span class="o">+=</span> <span class="p">[</span>
            <span class="n">check_ops</span><span class="o">.</span><span class="n">assert_greater_equal</span><span class="p">(</span>
                <span class="n">x</span><span class="p">,</span> <span class="n">_smallest_integer_by_dtype</span><span class="p">(</span><span class="n">target_dtype</span><span class="p">),</span>
                <span class="n">message</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;Elements cannot be smaller than </span><span class="si">{}</span><span class="s2">.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="n">_smallest_integer_by_dtype</span><span class="p">(</span><span class="n">target_dtype</span><span class="p">)))),</span>
        <span class="p">]</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">assertions</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">x</span>
    <span class="k">return</span> <span class="n">control_flow_ops</span><span class="o">.</span><span class="n">with_dependencies</span><span class="p">(</span><span class="n">assertions</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">log_combinations</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">counts</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;log_combinations&quot;</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Multinomial coefficient.</span>

<span class="sd">  Given `n` and `counts`, where `counts` has last dimension `k`, we compute</span>
<span class="sd">  the multinomial coefficient as:</span>

<span class="sd">  ```n! / sum_i n_i!```</span>

<span class="sd">  where `i` runs over all `k` classes.</span>

<span class="sd">  Args:</span>
<span class="sd">    n: Floating-point `Tensor` broadcastable with `counts`. This represents `n`</span>
<span class="sd">      outcomes.</span>
<span class="sd">    counts: Floating-point `Tensor` broadcastable with `n`. This represents</span>
<span class="sd">      counts in `k` classes, where `k` is the last dimension of the tensor.</span>
<span class="sd">    name: A name for this operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    `Tensor` representing the multinomial coefficient between `n` and `counts`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="c1"># First a bit about the number of ways counts could have come in:</span>
  <span class="c1"># E.g. if counts = [1, 2], then this is 3 choose 2.</span>
  <span class="c1"># In general, this is (sum counts)! / sum(counts!)</span>
  <span class="c1"># The sum should be along the last dimension of counts. This is the</span>
  <span class="c1"># &quot;distribution&quot; dimension. Here n a priori represents the sum of counts.</span>
  <span class="k">with</span> <span class="n">ops</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="p">[</span><span class="n">n</span><span class="p">,</span> <span class="n">counts</span><span class="p">]):</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;n&quot;</span><span class="p">)</span>
    <span class="n">counts</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">counts</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;counts&quot;</span><span class="p">)</span>
    <span class="n">total_permutations</span> <span class="o">=</span> <span class="n">math_ops</span><span class="o">.</span><span class="n">lgamma</span><span class="p">(</span><span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">counts_factorial</span> <span class="o">=</span> <span class="n">math_ops</span><span class="o">.</span><span class="n">lgamma</span><span class="p">(</span><span class="n">counts</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">redundant_permutations</span> <span class="o">=</span> <span class="n">math_ops</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">counts_factorial</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">total_permutations</span> <span class="o">-</span> <span class="n">redundant_permutations</span>


<span class="k">def</span> <span class="nf">matrix_diag_transform</span><span class="p">(</span><span class="n">matrix</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Transform diagonal of [batch-]matrix, leave rest of matrix unchanged.</span>

<span class="sd">  Create a trainable covariance defined by a Cholesky factor:</span>

<span class="sd">  ```python</span>
<span class="sd">  # Transform network layer into 2 x 2 array.</span>
<span class="sd">  matrix_values = tf.contrib.layers.fully_connected(activations, 4)</span>
<span class="sd">  matrix = tf.reshape(matrix_values, (batch_size, 2, 2))</span>

<span class="sd">  # Make the diagonal positive. If the upper triangle was zero, this would be a</span>
<span class="sd">  # valid Cholesky factor.</span>
<span class="sd">  chol = matrix_diag_transform(matrix, transform=tf.nn.softplus)</span>

<span class="sd">  # LinearOperatorLowerTriangular ignores the upper triangle.</span>
<span class="sd">  operator = LinearOperatorLowerTriangular(chol)</span>
<span class="sd">  ```</span>

<span class="sd">  Example of heteroskedastic 2-D linear regression.</span>

<span class="sd">  ```python</span>
<span class="sd">  tfd = tfp.distributions</span>

<span class="sd">  # Get a trainable Cholesky factor.</span>
<span class="sd">  matrix_values = tf.contrib.layers.fully_connected(activations, 4)</span>
<span class="sd">  matrix = tf.reshape(matrix_values, (batch_size, 2, 2))</span>
<span class="sd">  chol = matrix_diag_transform(matrix, transform=tf.nn.softplus)</span>

<span class="sd">  # Get a trainable mean.</span>
<span class="sd">  mu = tf.contrib.layers.fully_connected(activations, 2)</span>

<span class="sd">  # This is a fully trainable multivariate normal!</span>
<span class="sd">  dist = tfd.MultivariateNormalTriL(mu, chol)</span>

<span class="sd">  # Standard log loss. Minimizing this will &quot;train&quot; mu and chol, and then dist</span>
<span class="sd">  # will be a distribution predicting labels as multivariate Gaussians.</span>
<span class="sd">  loss = -1 * tf.reduce_mean(dist.log_prob(labels))</span>
<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    matrix:  Rank `R` `Tensor`, `R &gt;= 2`, where the last two dimensions are</span>
<span class="sd">      equal.</span>
<span class="sd">    transform:  Element-wise function mapping `Tensors` to `Tensors`. To</span>
<span class="sd">      be applied to the diagonal of `matrix`. If `None`, `matrix` is returned</span>
<span class="sd">      unchanged. Defaults to `None`.</span>
<span class="sd">    name:  A name to give created ops.</span>
<span class="sd">      Defaults to &quot;matrix_diag_transform&quot;.</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor` with same shape and `dtype` as `matrix`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">with</span> <span class="n">ops</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s2">&quot;matrix_diag_transform&quot;</span><span class="p">,</span> <span class="p">[</span><span class="n">matrix</span><span class="p">]):</span>
    <span class="n">matrix</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">matrix</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;matrix&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">transform</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">matrix</span>
    <span class="c1"># Replace the diag with transformed diag.</span>
    <span class="n">diag</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">matrix_diag_part</span><span class="p">(</span><span class="n">matrix</span><span class="p">)</span>
    <span class="n">transformed_diag</span> <span class="o">=</span> <span class="n">transform</span><span class="p">(</span><span class="n">diag</span><span class="p">)</span>
    <span class="n">transformed_mat</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">matrix_set_diag</span><span class="p">(</span><span class="n">matrix</span><span class="p">,</span> <span class="n">transformed_diag</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">transformed_mat</span>


<span class="k">def</span> <span class="nf">rotate_transpose</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">shift</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;rotate_transpose&quot;</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Circularly moves dims left or right.</span>

<span class="sd">  Effectively identical to:</span>

<span class="sd">  ```python</span>
<span class="sd">  numpy.transpose(x, numpy.roll(numpy.arange(len(x.shape)), shift))</span>
<span class="sd">  ```</span>

<span class="sd">  When `validate_args=False` additional graph-runtime checks are</span>
<span class="sd">  performed. These checks entail moving data from to GPU to CPU.</span>

<span class="sd">  Example:</span>

<span class="sd">  ```python</span>
<span class="sd">  x = tf.random_normal([1, 2, 3, 4])  # Tensor of shape [1, 2, 3, 4].</span>
<span class="sd">  rotate_transpose(x, -1).shape == [2, 3, 4, 1]</span>
<span class="sd">  rotate_transpose(x, -2).shape == [3, 4, 1, 2]</span>
<span class="sd">  rotate_transpose(x,  1).shape == [4, 1, 2, 3]</span>
<span class="sd">  rotate_transpose(x,  2).shape == [3, 4, 1, 2]</span>
<span class="sd">  rotate_transpose(x,  7).shape == rotate_transpose(x, 3).shape  # [2, 3, 4, 1]</span>
<span class="sd">  rotate_transpose(x, -7).shape == rotate_transpose(x, -3).shape  # [4, 1, 2, 3]</span>
<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    x: `Tensor`.</span>
<span class="sd">    shift: `Tensor`. Number of dimensions to transpose left (shift&lt;0) or</span>
<span class="sd">      transpose right (shift&gt;0).</span>
<span class="sd">    name: Python `str`. The name to give this op.</span>

<span class="sd">  Returns:</span>
<span class="sd">    rotated_x: Input `Tensor` with dimensions circularly rotated by shift.</span>

<span class="sd">  Raises:</span>
<span class="sd">    TypeError: if shift is not integer type.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">with</span> <span class="n">ops</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">shift</span><span class="p">]):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;x&quot;</span><span class="p">)</span>
    <span class="n">shift</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">shift</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;shift&quot;</span><span class="p">)</span>
    <span class="c1"># We do not assign back to preserve constant-ness.</span>
    <span class="n">check_ops</span><span class="o">.</span><span class="n">assert_integer</span><span class="p">(</span><span class="n">shift</span><span class="p">)</span>
    <span class="n">shift_value_static</span> <span class="o">=</span> <span class="n">tensor_util</span><span class="o">.</span><span class="n">constant_value</span><span class="p">(</span><span class="n">shift</span><span class="p">)</span>
    <span class="n">ndims</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span><span class="o">.</span><span class="n">ndims</span>
    <span class="k">if</span> <span class="n">ndims</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">shift_value_static</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">if</span> <span class="n">ndims</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span> <span class="k">return</span> <span class="n">x</span>
      <span class="n">shift_value_static</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">shift_value_static</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span>
          <span class="nb">abs</span><span class="p">(</span><span class="n">shift_value_static</span><span class="p">)</span> <span class="o">%</span> <span class="n">ndims</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">shift_value_static</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span> <span class="k">return</span> <span class="n">x</span>
      <span class="n">perm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">roll</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">ndims</span><span class="p">),</span> <span class="n">shift_value_static</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">perm</span><span class="o">=</span><span class="n">perm</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="c1"># Consider if we always had a positive shift, and some specified</span>
      <span class="c1"># direction.</span>
      <span class="c1"># When shifting left we want the new array:</span>
      <span class="c1">#   last(x, n-shift) + first(x, shift)</span>
      <span class="c1"># and if shifting right then we want:</span>
      <span class="c1">#   last(x, shift) + first(x, n-shift)</span>
      <span class="c1"># Observe that last(a) == slice(a, n) and first(a) == slice(0, a).</span>
      <span class="c1"># Also, we can encode direction and shift as one: direction * shift.</span>
      <span class="c1"># Combining these facts, we have:</span>
      <span class="c1">#   a = cond(shift&lt;0, -shift, n-shift)</span>
      <span class="c1">#   last(x, n-a) + first(x, a) == x[a:n] + x[0:a]</span>
      <span class="c1"># Finally, we transform shift by modulo length so it can be specified</span>
      <span class="c1"># independently from the array upon which it operates (like python).</span>
      <span class="n">ndims</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">rank</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
      <span class="n">shift</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">math_ops</span><span class="o">.</span><span class="n">less</span><span class="p">(</span><span class="n">shift</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
                              <span class="n">math_ops</span><span class="o">.</span><span class="n">mod</span><span class="p">(</span><span class="o">-</span><span class="n">shift</span><span class="p">,</span> <span class="n">ndims</span><span class="p">),</span>
                              <span class="n">ndims</span> <span class="o">-</span> <span class="n">math_ops</span><span class="o">.</span><span class="n">mod</span><span class="p">(</span><span class="n">shift</span><span class="p">,</span> <span class="n">ndims</span><span class="p">))</span>
      <span class="n">first</span> <span class="o">=</span> <span class="n">math_ops</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">shift</span><span class="p">)</span>
      <span class="n">last</span> <span class="o">=</span> <span class="n">math_ops</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">shift</span><span class="p">,</span> <span class="n">ndims</span><span class="p">)</span>
      <span class="n">perm</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">last</span><span class="p">,</span> <span class="n">first</span><span class="p">],</span> <span class="mi">0</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">perm</span><span class="o">=</span><span class="n">perm</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">pick_vector</span><span class="p">(</span><span class="n">cond</span><span class="p">,</span>
                <span class="n">true_vector</span><span class="p">,</span>
                <span class="n">false_vector</span><span class="p">,</span>
                <span class="n">name</span><span class="o">=</span><span class="s2">&quot;pick_vector&quot;</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Picks possibly different length row `Tensor`s based on condition.</span>

<span class="sd">  Value `Tensor`s should have exactly one dimension.</span>

<span class="sd">  If `cond` is a python Boolean or `tf.constant` then either `true_vector` or</span>
<span class="sd">  `false_vector` is immediately returned. I.e., no graph nodes are created and</span>
<span class="sd">  no validation happens.</span>

<span class="sd">  Args:</span>
<span class="sd">    cond: `Tensor`. Must have `dtype=tf.bool` and be scalar.</span>
<span class="sd">    true_vector: `Tensor` of one dimension. Returned when cond is `True`.</span>
<span class="sd">    false_vector: `Tensor` of one dimension. Returned when cond is `False`.</span>
<span class="sd">    name: Python `str`. The name to give this op.</span>

<span class="sd">  Example:</span>

<span class="sd">  ```python</span>
<span class="sd">  pick_vector(tf.less(0, 5), tf.range(10, 12), tf.range(15, 18))  # [10, 11]</span>
<span class="sd">  pick_vector(tf.less(5, 0), tf.range(10, 12), tf.range(15, 18))  # [15, 16, 17]</span>
<span class="sd">  ```</span>

<span class="sd">  Returns:</span>
<span class="sd">    true_or_false_vector: `Tensor`.</span>

<span class="sd">  Raises:</span>
<span class="sd">    TypeError: if `cond.dtype != tf.bool`</span>
<span class="sd">    TypeError: if `cond` is not a constant and</span>
<span class="sd">      `true_vector.dtype != false_vector.dtype`</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">with</span> <span class="n">ops</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="p">(</span><span class="n">cond</span><span class="p">,</span> <span class="n">true_vector</span><span class="p">,</span> <span class="n">false_vector</span><span class="p">)):</span>
    <span class="n">cond</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">cond</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;cond&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">cond</span><span class="o">.</span><span class="n">dtype</span> <span class="o">!=</span> <span class="n">dtypes</span><span class="o">.</span><span class="n">bool</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2">.dtype=</span><span class="si">%s</span><span class="s2"> which is not </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span>
                      <span class="p">(</span><span class="n">cond</span><span class="p">,</span> <span class="n">cond</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">dtypes</span><span class="o">.</span><span class="n">bool</span><span class="p">))</span>
    <span class="n">cond_value_static</span> <span class="o">=</span> <span class="n">tensor_util</span><span class="o">.</span><span class="n">constant_value</span><span class="p">(</span><span class="n">cond</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">cond_value_static</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">true_vector</span> <span class="k">if</span> <span class="n">cond_value_static</span> <span class="k">else</span> <span class="n">false_vector</span>
    <span class="n">true_vector</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">true_vector</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;true_vector&quot;</span><span class="p">)</span>
    <span class="n">false_vector</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">false_vector</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;false_vector&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">true_vector</span><span class="o">.</span><span class="n">dtype</span> <span class="o">!=</span> <span class="n">false_vector</span><span class="o">.</span><span class="n">dtype</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
          <span class="s2">&quot;</span><span class="si">%s</span><span class="s2">.dtype=</span><span class="si">%s</span><span class="s2"> does not match </span><span class="si">%s</span><span class="s2">.dtype=</span><span class="si">%s</span><span class="s2">&quot;</span>
          <span class="o">%</span> <span class="p">(</span><span class="n">true_vector</span><span class="p">,</span> <span class="n">true_vector</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
             <span class="n">false_vector</span><span class="p">,</span> <span class="n">false_vector</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">true_vector</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">slice</span><span class="p">(</span>
        <span class="n">array_ops</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">true_vector</span><span class="p">,</span> <span class="n">false_vector</span><span class="p">],</span> <span class="mi">0</span><span class="p">),</span>
        <span class="p">[</span><span class="n">array_ops</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">cond</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">n</span><span class="p">)],</span> <span class="p">[</span><span class="n">array_ops</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">cond</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)])</span>


<span class="k">def</span> <span class="nf">prefer_static_broadcast_shape</span><span class="p">(</span>
    <span class="n">shape1</span><span class="p">,</span> <span class="n">shape2</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;prefer_static_broadcast_shape&quot;</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Convenience function which statically broadcasts shape when possible.</span>

<span class="sd">  Args:</span>
<span class="sd">    shape1:  `1-D` integer `Tensor`.  Already converted to tensor!</span>
<span class="sd">    shape2:  `1-D` integer `Tensor`.  Already converted to tensor!</span>
<span class="sd">    name:  A string name to prepend to created ops.</span>

<span class="sd">  Returns:</span>
<span class="sd">    The broadcast shape, either as `TensorShape` (if broadcast can be done</span>
<span class="sd">      statically), or as a `Tensor`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">with</span> <span class="n">ops</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="p">[</span><span class="n">shape1</span><span class="p">,</span> <span class="n">shape2</span><span class="p">]):</span>
    <span class="k">def</span> <span class="nf">make_shape_tensor</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
      <span class="k">return</span> <span class="n">ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;shape&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_tensor_shape</span><span class="p">(</span><span class="n">s</span><span class="p">):</span>
      <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">tensor_shape</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">s</span>
      <span class="n">s_</span> <span class="o">=</span> <span class="n">tensor_util</span><span class="o">.</span><span class="n">constant_value</span><span class="p">(</span><span class="n">make_shape_tensor</span><span class="p">(</span><span class="n">s</span><span class="p">))</span>
      <span class="k">if</span> <span class="n">s_</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">tensor_shape</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">(</span><span class="n">s_</span><span class="p">)</span>
      <span class="k">return</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">get_shape_tensor</span><span class="p">(</span><span class="n">s</span><span class="p">):</span>
      <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">tensor_shape</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">make_shape_tensor</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">s</span><span class="o">.</span><span class="n">is_fully_defined</span><span class="p">():</span>
        <span class="k">return</span> <span class="n">make_shape_tensor</span><span class="p">(</span><span class="n">s</span><span class="o">.</span><span class="n">as_list</span><span class="p">())</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Cannot broadcast from partially &quot;</span>
                       <span class="s2">&quot;defined `TensorShape`.&quot;</span><span class="p">)</span>

    <span class="n">shape1_</span> <span class="o">=</span> <span class="n">get_tensor_shape</span><span class="p">(</span><span class="n">shape1</span><span class="p">)</span>
    <span class="n">shape2_</span> <span class="o">=</span> <span class="n">get_tensor_shape</span><span class="p">(</span><span class="n">shape2</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">shape1_</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">shape2_</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">broadcast_static_shape</span><span class="p">(</span><span class="n">shape1_</span><span class="p">,</span> <span class="n">shape2_</span><span class="p">)</span>

    <span class="n">shape1_</span> <span class="o">=</span> <span class="n">get_shape_tensor</span><span class="p">(</span><span class="n">shape1</span><span class="p">)</span>
    <span class="n">shape2_</span> <span class="o">=</span> <span class="n">get_shape_tensor</span><span class="p">(</span><span class="n">shape2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">broadcast_dynamic_shape</span><span class="p">(</span><span class="n">shape1_</span><span class="p">,</span> <span class="n">shape2_</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">prefer_static_rank</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Return static rank of tensor `x` if available, else `tf.rank(x)`.</span>

<span class="sd">  Args:</span>
<span class="sd">    x: `Tensor` (already converted).</span>

<span class="sd">  Returns:</span>
<span class="sd">    Numpy array (if static rank is obtainable), else `Tensor`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">return</span> <span class="n">prefer_static_value</span><span class="p">(</span><span class="n">array_ops</span><span class="o">.</span><span class="n">rank</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">prefer_static_shape</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Return static shape of tensor `x` if available, else `tf.shape(x)`.</span>

<span class="sd">  Args:</span>
<span class="sd">    x: `Tensor` (already converted).</span>

<span class="sd">  Returns:</span>
<span class="sd">    Numpy array (if static shape is obtainable), else `Tensor`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">return</span> <span class="n">prefer_static_value</span><span class="p">(</span><span class="n">array_ops</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">prefer_static_value</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Return static value of tensor `x` if available, else `x`.</span>

<span class="sd">  Args:</span>
<span class="sd">    x: `Tensor` (already converted).</span>

<span class="sd">  Returns:</span>
<span class="sd">    Numpy array (if static value is obtainable), else `Tensor`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">static_x</span> <span class="o">=</span> <span class="n">tensor_util</span><span class="o">.</span><span class="n">constant_value</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">static_x</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">static_x</span>
  <span class="k">return</span> <span class="n">x</span>


<span class="k">def</span> <span class="nf">gen_new_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">,</span> <span class="n">salt</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Generate a new seed, from the given seed and salt.&quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="n">seed</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="k">return</span> <span class="kc">None</span>
  <span class="n">string</span> <span class="o">=</span> <span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span> <span class="o">+</span> <span class="n">salt</span><span class="p">)</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s2">&quot;utf-8&quot;</span><span class="p">)</span>
  <span class="k">return</span> <span class="nb">int</span><span class="p">(</span><span class="n">hashlib</span><span class="o">.</span><span class="n">md5</span><span class="p">(</span><span class="n">string</span><span class="p">)</span><span class="o">.</span><span class="n">hexdigest</span><span class="p">()[:</span><span class="mi">8</span><span class="p">],</span> <span class="mi">16</span><span class="p">)</span> <span class="o">&amp;</span> <span class="mh">0x7FFFFFFF</span>


<span class="k">def</span> <span class="nf">fill_triangular</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Creates a (batch of) triangular matrix from a vector of inputs.</span>

<span class="sd">  Created matrix can be lower- or upper-triangular. (It is more efficient to</span>
<span class="sd">  create the matrix as upper or lower, rather than transpose.)</span>

<span class="sd">  Triangular matrix elements are filled in a clockwise spiral. See example,</span>
<span class="sd">  below.</span>

<span class="sd">  If `x.get_shape()` is `[b1, b2, ..., bB, d]` then the output shape is</span>
<span class="sd">  `[b1, b2, ..., bB, n, n]` where `n` is such that `d = n(n+1)/2`, i.e.,</span>
<span class="sd">  `n = int(np.sqrt(0.25 + 2. * m) - 0.5)`.</span>

<span class="sd">  Example:</span>

<span class="sd">  ```python</span>
<span class="sd">  fill_triangular([1, 2, 3, 4, 5, 6])</span>
<span class="sd">  # ==&gt; [[4, 0, 0],</span>
<span class="sd">  #      [6, 5, 0],</span>
<span class="sd">  #      [3, 2, 1]]</span>

<span class="sd">  fill_triangular([1, 2, 3, 4, 5, 6], upper=True)</span>
<span class="sd">  # ==&gt; [[1, 2, 3],</span>
<span class="sd">  #      [0, 5, 6],</span>
<span class="sd">  #      [0, 0, 4]]</span>
<span class="sd">  ```</span>

<span class="sd">  For comparison, a pure numpy version of this function can be found in</span>
<span class="sd">  `util_test.py`, function `_fill_triangular`.</span>

<span class="sd">  Args:</span>
<span class="sd">    x: `Tensor` representing lower (or upper) triangular elements.</span>
<span class="sd">    upper: Python `bool` representing whether output matrix should be upper</span>
<span class="sd">      triangular (`True`) or lower triangular (`False`, default).</span>
<span class="sd">    name: Python `str`. The name to give this op.</span>

<span class="sd">  Returns:</span>
<span class="sd">    tril: `Tensor` with lower (or upper) triangular elements filled from `x`.</span>

<span class="sd">  Raises:</span>
<span class="sd">    ValueError: if `x` cannot be mapped to a triangular matrix.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">with</span> <span class="n">ops</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s2">&quot;fill_triangular&quot;</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="p">[</span><span class="n">x</span><span class="p">]):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;x&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">tensor_shape</span><span class="o">.</span><span class="n">dimension_value</span><span class="p">(</span>
        <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">with_rank_at_least</span><span class="p">(</span><span class="mi">1</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="c1"># Formula derived by solving for n: m = n(n+1)/2.</span>
      <span class="n">m</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">dims</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
      <span class="n">n</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">0.25</span> <span class="o">+</span> <span class="mf">2.</span> <span class="o">*</span> <span class="n">m</span><span class="p">)</span> <span class="o">-</span> <span class="mf">0.5</span>
      <span class="k">if</span> <span class="n">n</span> <span class="o">!=</span> <span class="n">np</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Input right-most shape (</span><span class="si">{}</span><span class="s2">) does not &quot;</span>
                         <span class="s2">&quot;correspond to a triangular matrix.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">m</span><span class="p">))</span>
      <span class="n">n</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
      <span class="n">static_final_shape</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">m</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
      <span class="c1"># For derivation, see above. Casting automatically lops off the 0.5, so we</span>
      <span class="c1"># omit it.  We don&#39;t validate n is an integer because this has</span>
      <span class="c1"># graph-execution cost; an error will be thrown from the reshape, below.</span>
      <span class="n">n</span> <span class="o">=</span> <span class="n">math_ops</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span>
          <span class="n">math_ops</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">0.25</span> <span class="o">+</span> <span class="n">math_ops</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">m</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtypes</span><span class="o">.</span><span class="n">float32</span><span class="p">)),</span>
          <span class="n">dtype</span><span class="o">=</span><span class="n">dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
      <span class="n">static_final_shape</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">with_rank_at_least</span><span class="p">(</span><span class="mi">1</span><span class="p">)[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span>
          <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">])</span>
    <span class="c1"># We now concatenate the &quot;tail&quot; of `x` to `x` (and reverse one of them).</span>
    <span class="c1">#</span>
    <span class="c1"># We do this based on the insight that the input `x` provides `ceil(n/2)`</span>
    <span class="c1"># rows of an `n x n` matrix, some of which will get zeroed out being on the</span>
    <span class="c1"># wrong side of the diagonal. The first row will not get zeroed out at all,</span>
    <span class="c1"># and we need `floor(n/2)` more rows, so the first is what we omit from</span>
    <span class="c1"># `x_tail`. If we then stack those `ceil(n/2)` rows with the `floor(n/2)`</span>
    <span class="c1"># rows provided by a reversed tail, it is exactly the other set of elements</span>
    <span class="c1"># of the reversed tail which will be zeroed out for being on the wrong side</span>
    <span class="c1"># of the diagonal further up/down the matrix. And, in doing-so, we&#39;ve filled</span>
    <span class="c1"># the triangular matrix in a clock-wise spiral pattern. Neat!</span>
    <span class="c1">#</span>
    <span class="c1"># Try it out in numpy:</span>
    <span class="c1">#  n = 3</span>
    <span class="c1">#  x = np.arange(n * (n + 1) / 2)</span>
    <span class="c1">#  m = x.shape[0]</span>
    <span class="c1">#  n = np.int32(np.sqrt(.25 + 2 * m) - .5)</span>
    <span class="c1">#  x_tail = x[(m - (n**2 - m)):]</span>
    <span class="c1">#  np.concatenate([x_tail, x[::-1]], 0).reshape(n, n)  # lower</span>
    <span class="c1">#  # ==&gt; array([[3, 4, 5],</span>
    <span class="c1">#               [5, 4, 3],</span>
    <span class="c1">#               [2, 1, 0]])</span>
    <span class="c1">#  np.concatenate([x, x_tail[::-1]], 0).reshape(n, n)  # upper</span>
    <span class="c1">#  # ==&gt; array([[0, 1, 2],</span>
    <span class="c1">#               [3, 4, 5],</span>
    <span class="c1">#               [5, 4, 3]])</span>
    <span class="c1">#</span>
    <span class="c1"># Note that we can&#39;t simply do `x[..., -(n**2 - m):]` because this doesn&#39;t</span>
    <span class="c1"># correctly handle `m == n == 1`. Hence, we do nonnegative indexing.</span>
    <span class="c1"># Furthermore observe that:</span>
    <span class="c1">#   m - (n**2 - m)</span>
    <span class="c1">#   = n**2 / 2 + n / 2 - (n**2 - n**2 / 2 + n / 2)</span>
    <span class="c1">#   = 2 (n**2 / 2 + n / 2) - n**2</span>
    <span class="c1">#   = n**2 + n - n**2</span>
    <span class="c1">#   = n</span>
    <span class="n">ndims</span> <span class="o">=</span> <span class="n">prefer_static_rank</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">upper</span><span class="p">:</span>
      <span class="n">x_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">reverse</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">n</span><span class="p">:],</span> <span class="n">axis</span><span class="o">=</span><span class="p">[</span><span class="n">ndims</span> <span class="o">-</span> <span class="mi">1</span><span class="p">])]</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">x_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">n</span><span class="p">:],</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">reverse</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="p">[</span><span class="n">ndims</span> <span class="o">-</span> <span class="mi">1</span><span class="p">])]</span>
    <span class="n">new_shape</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">static_final_shape</span><span class="o">.</span><span class="n">as_list</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">static_final_shape</span><span class="o">.</span><span class="n">is_fully_defined</span><span class="p">()</span>
        <span class="k">else</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">array_ops</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">)[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="p">]],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">array_ops</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">x_list</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span> <span class="n">new_shape</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">matrix_band_part</span><span class="p">(</span>
        <span class="n">x</span><span class="p">,</span>
        <span class="n">num_lower</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span> <span class="k">if</span> <span class="n">upper</span> <span class="k">else</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">num_upper</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span> <span class="k">if</span> <span class="n">upper</span> <span class="k">else</span> <span class="mi">0</span><span class="p">))</span>
    <span class="n">x</span><span class="o">.</span><span class="n">set_shape</span><span class="p">(</span><span class="n">static_final_shape</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span>


<span class="k">def</span> <span class="nf">fill_triangular_inverse</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Creates a vector from a (batch of) triangular matrix.</span>

<span class="sd">  The vector is created from the lower-triangular or upper-triangular portion</span>
<span class="sd">  depending on the value of the parameter `upper`.</span>

<span class="sd">  If `x.shape` is `[b1, b2, ..., bB, n, n]` then the output shape is</span>
<span class="sd">  `[b1, b2, ..., bB, d]` where `d = n (n + 1) / 2`.</span>

<span class="sd">  Example:</span>

<span class="sd">  ```python</span>
<span class="sd">  fill_triangular_inverse(</span>
<span class="sd">    [[4, 0, 0],</span>
<span class="sd">     [6, 5, 0],</span>
<span class="sd">     [3, 2, 1]])</span>

<span class="sd">  # ==&gt; [1, 2, 3, 4, 5, 6]</span>

<span class="sd">  fill_triangular_inverse(</span>
<span class="sd">    [[1, 2, 3],</span>
<span class="sd">     [0, 5, 6],</span>
<span class="sd">     [0, 0, 4]], upper=True)</span>

<span class="sd">  # ==&gt; [1, 2, 3, 4, 5, 6]</span>
<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    x: `Tensor` representing lower (or upper) triangular elements.</span>
<span class="sd">    upper: Python `bool` representing whether output matrix should be upper</span>
<span class="sd">      triangular (`True`) or lower triangular (`False`, default).</span>
<span class="sd">    name: Python `str`. The name to give this op.</span>

<span class="sd">  Returns:</span>
<span class="sd">    flat_tril: (Batch of) vector-shaped `Tensor` representing vectorized lower</span>
<span class="sd">      (or upper) triangular elements from `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">with</span> <span class="n">ops</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s2">&quot;fill_triangular_inverse&quot;</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="p">[</span><span class="n">x</span><span class="p">]):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;x&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">tensor_shape</span><span class="o">.</span><span class="n">dimension_value</span><span class="p">(</span>
        <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">with_rank_at_least</span><span class="p">(</span><span class="mi">2</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">n</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">dims</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
      <span class="n">m</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">((</span><span class="n">n</span> <span class="o">*</span> <span class="p">(</span><span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span> <span class="o">//</span> <span class="mi">2</span><span class="p">)</span>
      <span class="n">static_final_shape</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">m</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">n</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
      <span class="n">m</span> <span class="o">=</span> <span class="p">(</span><span class="n">n</span> <span class="o">*</span> <span class="p">(</span><span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span> <span class="o">//</span> <span class="mi">2</span>
      <span class="n">static_final_shape</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">with_rank_at_least</span><span class="p">(</span><span class="mi">2</span><span class="p">)[:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span>
          <span class="p">[</span><span class="kc">None</span><span class="p">])</span>
    <span class="n">ndims</span> <span class="o">=</span> <span class="n">prefer_static_rank</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">upper</span><span class="p">:</span>
      <span class="n">initial_elements</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:]</span>
      <span class="n">triangular_portion</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">1</span><span class="p">:,</span> <span class="p">:]</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">initial_elements</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">reverse</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:],</span> <span class="n">axis</span><span class="o">=</span><span class="p">[</span><span class="n">ndims</span> <span class="o">-</span> <span class="mi">2</span><span class="p">])</span>
      <span class="n">triangular_portion</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>
    <span class="n">rotated_triangular_portion</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">reverse</span><span class="p">(</span>
        <span class="n">array_ops</span><span class="o">.</span><span class="n">reverse</span><span class="p">(</span><span class="n">triangular_portion</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="p">[</span><span class="n">ndims</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]),</span>
        <span class="n">axis</span><span class="o">=</span><span class="p">[</span><span class="n">ndims</span> <span class="o">-</span> <span class="mi">2</span><span class="p">])</span>
    <span class="n">consolidated_matrix</span> <span class="o">=</span> <span class="n">triangular_portion</span> <span class="o">+</span> <span class="n">rotated_triangular_portion</span>
    <span class="n">end_sequence</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
        <span class="n">consolidated_matrix</span><span class="p">,</span>
        <span class="n">array_ops</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">array_ops</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">)[:</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="n">n</span> <span class="o">*</span> <span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)]],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">initial_elements</span><span class="p">,</span> <span class="n">end_sequence</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="n">m</span> <span class="o">-</span> <span class="n">n</span><span class="p">]],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">y</span><span class="o">.</span><span class="n">set_shape</span><span class="p">(</span><span class="n">static_final_shape</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">y</span>


<span class="k">def</span> <span class="nf">tridiag</span><span class="p">(</span><span class="n">below</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">diag</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">above</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Creates a matrix with values set above, below, and on the diagonal.</span>

<span class="sd">  Example:</span>

<span class="sd">  ```python</span>
<span class="sd">  tridiag(below=[1., 2., 3.],</span>
<span class="sd">          diag=[4., 5., 6., 7.],</span>
<span class="sd">          above=[8., 9., 10.])</span>
<span class="sd">  # ==&gt; array([[  4.,   8.,   0.,   0.],</span>
<span class="sd">  #            [  1.,   5.,   9.,   0.],</span>
<span class="sd">  #            [  0.,   2.,   6.,  10.],</span>
<span class="sd">  #            [  0.,   0.,   3.,   7.]], dtype=float32)</span>
<span class="sd">  ```</span>

<span class="sd">  Warning: This Op is intended for convenience, not efficiency.</span>

<span class="sd">  Args:</span>
<span class="sd">    below: `Tensor` of shape `[B1, ..., Bb, d-1]` corresponding to the below</span>
<span class="sd">      diagonal part. `None` is logically equivalent to `below = 0`.</span>
<span class="sd">    diag: `Tensor` of shape `[B1, ..., Bb, d]` corresponding to the diagonal</span>
<span class="sd">      part.  `None` is logically equivalent to `diag = 0`.</span>
<span class="sd">    above: `Tensor` of shape `[B1, ..., Bb, d-1]` corresponding to the above</span>
<span class="sd">      diagonal part.  `None` is logically equivalent to `above = 0`.</span>
<span class="sd">    name: Python `str`. The name to give this op.</span>

<span class="sd">  Returns:</span>
<span class="sd">    tridiag: `Tensor` with values set above, below and on the diagonal.</span>

<span class="sd">  Raises:</span>
<span class="sd">    ValueError: if all inputs are `None`.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="nf">_pad</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Prepends and appends a zero to every vector in a batch of vectors.&quot;&quot;&quot;</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">array_ops</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">)[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">]],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">z</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">z</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_add</span><span class="p">(</span><span class="o">*</span><span class="n">x</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Adds list of Tensors, ignoring `None`.&quot;&quot;&quot;</span>
    <span class="n">s</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">x</span><span class="p">:</span>
      <span class="k">if</span> <span class="n">y</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">continue</span>
      <span class="k">elif</span> <span class="n">s</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">s</span> <span class="o">=</span> <span class="n">y</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">s</span> <span class="o">+=</span> <span class="n">y</span>
    <span class="k">if</span> <span class="n">s</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Must specify at least one of `below`, `diag`, `above`.&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">s</span>

  <span class="k">with</span> <span class="n">ops</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s2">&quot;tridiag&quot;</span><span class="p">,</span> <span class="p">[</span><span class="n">below</span><span class="p">,</span> <span class="n">diag</span><span class="p">,</span> <span class="n">above</span><span class="p">]):</span>
    <span class="k">if</span> <span class="n">below</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">below</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">below</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;below&quot;</span><span class="p">)</span>
      <span class="n">below</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">matrix_diag</span><span class="p">(</span><span class="n">_pad</span><span class="p">(</span><span class="n">below</span><span class="p">))[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">:]</span>
    <span class="k">if</span> <span class="n">diag</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">diag</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">diag</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;diag&quot;</span><span class="p">)</span>
      <span class="n">diag</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">matrix_diag</span><span class="p">(</span><span class="n">diag</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">above</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">above</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">above</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;above&quot;</span><span class="p">)</span>
      <span class="n">above</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">matrix_diag</span><span class="p">(</span><span class="n">_pad</span><span class="p">(</span><span class="n">above</span><span class="p">))[</span><span class="o">...</span><span class="p">,</span> <span class="mi">1</span><span class="p">:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="c1"># TODO(jvdillon): Consider using scatter_nd instead of creating three full</span>
    <span class="c1"># matrices.</span>
    <span class="k">return</span> <span class="n">_add</span><span class="p">(</span><span class="n">below</span><span class="p">,</span> <span class="n">diag</span><span class="p">,</span> <span class="n">above</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">reduce_weighted_logsumexp</span><span class="p">(</span>
    <span class="n">logx</span><span class="p">,</span>
    <span class="n">w</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">axis</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">keep_dims</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">return_sign</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Computes `log(abs(sum(weight * exp(elements across tensor dimensions))))`.</span>

<span class="sd">  If all weights `w` are known to be positive, it is more efficient to directly</span>
<span class="sd">  use `reduce_logsumexp`, i.e., `tf.reduce_logsumexp(logx + tf.log(w))` is more</span>
<span class="sd">  efficient than `du.reduce_weighted_logsumexp(logx, w)`.</span>

<span class="sd">  Reduces `input_tensor` along the dimensions given in `axis`.</span>
<span class="sd">  Unless `keep_dims` is true, the rank of the tensor is reduced by 1 for each</span>
<span class="sd">  entry in `axis`. If `keep_dims` is true, the reduced dimensions</span>
<span class="sd">  are retained with length 1.</span>

<span class="sd">  If `axis` has no entries, all dimensions are reduced, and a</span>
<span class="sd">  tensor with a single element is returned.</span>

<span class="sd">  This function is more numerically stable than log(sum(w * exp(input))). It</span>
<span class="sd">  avoids overflows caused by taking the exp of large inputs and underflows</span>
<span class="sd">  caused by taking the log of small inputs.</span>

<span class="sd">  For example:</span>

<span class="sd">  ```python</span>
<span class="sd">  x = tf.constant([[0., 0, 0],</span>
<span class="sd">                   [0, 0, 0]])</span>

<span class="sd">  w = tf.constant([[-1., 1, 1],</span>
<span class="sd">                   [1, 1, 1]])</span>

<span class="sd">  du.reduce_weighted_logsumexp(x, w)</span>
<span class="sd">  # ==&gt; log(-1*1 + 1*1 + 1*1 + 1*1 + 1*1 + 1*1) = log(4)</span>

<span class="sd">  du.reduce_weighted_logsumexp(x, w, axis=0)</span>
<span class="sd">  # ==&gt; [log(-1+1), log(1+1), log(1+1)]</span>

<span class="sd">  du.reduce_weighted_logsumexp(x, w, axis=1)</span>
<span class="sd">  # ==&gt; [log(-1+1+1), log(1+1+1)]</span>

<span class="sd">  du.reduce_weighted_logsumexp(x, w, axis=1, keep_dims=True)</span>
<span class="sd">  # ==&gt; [[log(-1+1+1)], [log(1+1+1)]]</span>

<span class="sd">  du.reduce_weighted_logsumexp(x, w, axis=[0, 1])</span>
<span class="sd">  # ==&gt; log(-1+5)</span>
<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    logx: The tensor to reduce. Should have numeric type.</span>
<span class="sd">    w: The weight tensor. Should have numeric type identical to `logx`.</span>
<span class="sd">    axis: The dimensions to reduce. If `None` (the default),</span>
<span class="sd">      reduces all dimensions. Must be in the range</span>
<span class="sd">      `[-rank(input_tensor), rank(input_tensor))`.</span>
<span class="sd">    keep_dims: If true, retains reduced dimensions with length 1.</span>
<span class="sd">    return_sign: If `True`, returns the sign of the result.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    lswe: The `log(abs(sum(weight * exp(x))))` reduced tensor.</span>
<span class="sd">    sign: (Optional) The sign of `sum(weight * exp(x))`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">with</span> <span class="n">ops</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s2">&quot;reduce_weighted_logsumexp&quot;</span><span class="p">,</span> <span class="p">[</span><span class="n">logx</span><span class="p">,</span> <span class="n">w</span><span class="p">]):</span>
    <span class="n">logx</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">logx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;logx&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">w</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">lswe</span> <span class="o">=</span> <span class="n">math_ops</span><span class="o">.</span><span class="n">reduce_logsumexp</span><span class="p">(</span><span class="n">logx</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="n">keep_dims</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">return_sign</span><span class="p">:</span>
        <span class="n">sgn</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">lswe</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">lswe</span><span class="p">,</span> <span class="n">sgn</span>
      <span class="k">return</span> <span class="n">lswe</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">logx</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;w&quot;</span><span class="p">)</span>
    <span class="n">log_absw_x</span> <span class="o">=</span> <span class="n">logx</span> <span class="o">+</span> <span class="n">math_ops</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">math_ops</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">w</span><span class="p">))</span>
    <span class="n">max_log_absw_x</span> <span class="o">=</span> <span class="n">math_ops</span><span class="o">.</span><span class="n">reduce_max</span><span class="p">(</span><span class="n">log_absw_x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="c1"># If the largest element is `-inf` or `inf` then we don&#39;t bother subtracting</span>
    <span class="c1"># off the max. We do this because otherwise we&#39;d get `inf - inf = NaN`. That</span>
    <span class="c1"># this is ok follows from the fact that we&#39;re actually free to subtract any</span>
    <span class="c1"># value we like, so long as we add it back after taking the `log(sum(...))`.</span>
    <span class="n">max_log_absw_x</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
        <span class="n">math_ops</span><span class="o">.</span><span class="n">is_inf</span><span class="p">(</span><span class="n">max_log_absw_x</span><span class="p">),</span>
        <span class="n">array_ops</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">max_log_absw_x</span><span class="p">),</span>
        <span class="n">max_log_absw_x</span><span class="p">)</span>
    <span class="n">wx_over_max_absw_x</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">math_ops</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">w</span><span class="p">)</span> <span class="o">*</span> <span class="n">math_ops</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_absw_x</span> <span class="o">-</span> <span class="n">max_log_absw_x</span><span class="p">))</span>
    <span class="n">sum_wx_over_max_absw_x</span> <span class="o">=</span> <span class="n">math_ops</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span>
        <span class="n">wx_over_max_absw_x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="n">keep_dims</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">keep_dims</span><span class="p">:</span>
      <span class="n">max_log_absw_x</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">max_log_absw_x</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span>
    <span class="n">sgn</span> <span class="o">=</span> <span class="n">math_ops</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">sum_wx_over_max_absw_x</span><span class="p">)</span>
    <span class="n">lswe</span> <span class="o">=</span> <span class="n">max_log_absw_x</span> <span class="o">+</span> <span class="n">math_ops</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">sgn</span> <span class="o">*</span> <span class="n">sum_wx_over_max_absw_x</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">return_sign</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">lswe</span><span class="p">,</span> <span class="n">sgn</span>
    <span class="k">return</span> <span class="n">lswe</span>


<span class="c1"># TODO(jvdillon): Merge this test back into:</span>
<span class="c1"># tensorflow/python/ops/softplus_op_test.py</span>
<span class="c1"># once TF core is accepting new ops.</span>
<span class="k">def</span> <span class="nf">softplus_inverse</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Computes the inverse softplus, i.e., x = softplus_inverse(softplus(x)).</span>

<span class="sd">  Mathematically this op is equivalent to:</span>

<span class="sd">  ```none</span>
<span class="sd">  softplus_inverse = log(exp(x) - 1.)</span>
<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    x: `Tensor`. Non-negative (not enforced), floating-point.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    `Tensor`. Has the same type/shape as input `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">with</span> <span class="n">ops</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s2">&quot;softplus_inverse&quot;</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="p">[</span><span class="n">x</span><span class="p">]):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;x&quot;</span><span class="p">)</span>
    <span class="c1"># We begin by deriving a more numerically stable softplus_inverse:</span>
    <span class="c1"># x = softplus(y) = Log[1 + exp{y}], (which means x &gt; 0).</span>
    <span class="c1"># ==&gt; exp{x} = 1 + exp{y}                                (1)</span>
    <span class="c1"># ==&gt; y = Log[exp{x} - 1]                                (2)</span>
    <span class="c1">#       = Log[(exp{x} - 1) / exp{x}] + Log[exp{x}]</span>
    <span class="c1">#       = Log[(1 - exp{-x}) / 1] + Log[exp{x}]</span>
    <span class="c1">#       = Log[1 - exp{-x}] + x                           (3)</span>
    <span class="c1"># (2) is the &quot;obvious&quot; inverse, but (3) is more stable than (2) for large x.</span>
    <span class="c1"># For small x (e.g. x = 1e-10), (3) will become -inf since 1 - exp{-x} will</span>
    <span class="c1"># be zero. To fix this, we use 1 - exp{-x} approx x for small x &gt; 0.</span>
    <span class="c1">#</span>
    <span class="c1"># In addition to the numerically stable derivation above, we clamp</span>
    <span class="c1"># small/large values to be congruent with the logic in:</span>
    <span class="c1"># tensorflow/core/kernels/softplus_op.h</span>
    <span class="c1">#</span>
    <span class="c1"># Finally, we set the input to one whenever the input is too large or too</span>
    <span class="c1"># small. This ensures that no unchosen codepath is +/- inf. This is</span>
    <span class="c1"># necessary to ensure the gradient doesn&#39;t get NaNs. Recall that the</span>
    <span class="c1"># gradient of `where` behaves like `pred*pred_true + (1-pred)*pred_false`</span>
    <span class="c1"># thus an `inf` in an unselected path results in `0*inf=nan`. We are careful</span>
    <span class="c1"># to overwrite `x` with ones only when we will never actually use this</span>
    <span class="c1"># value. Note that we use ones and not zeros since `log(expm1(0.)) = -inf`.</span>
    <span class="n">threshold</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">as_numpy_dtype</span><span class="p">)</span><span class="o">.</span><span class="n">eps</span><span class="p">)</span> <span class="o">+</span> <span class="mf">2.</span>
    <span class="n">is_too_small</span> <span class="o">=</span> <span class="n">math_ops</span><span class="o">.</span><span class="n">less</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">threshold</span><span class="p">))</span>
    <span class="n">is_too_large</span> <span class="o">=</span> <span class="n">math_ops</span><span class="o">.</span><span class="n">greater</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="o">-</span><span class="n">threshold</span><span class="p">)</span>
    <span class="n">too_small_value</span> <span class="o">=</span> <span class="n">math_ops</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">too_large_value</span> <span class="o">=</span> <span class="n">x</span>
    <span class="c1"># This `where` will ultimately be a NOP because we won&#39;t select this</span>
    <span class="c1"># codepath whenever we used the surrogate `ones_like`.</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">math_ops</span><span class="o">.</span><span class="n">logical_or</span><span class="p">(</span><span class="n">is_too_small</span><span class="p">,</span> <span class="n">is_too_large</span><span class="p">),</span>
                        <span class="n">array_ops</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">x</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">math_ops</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="o">-</span><span class="n">math_ops</span><span class="o">.</span><span class="n">expm1</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">))</span>  <span class="c1"># == log(expm1(x))</span>
    <span class="k">return</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">is_too_small</span><span class="p">,</span> <span class="n">too_small_value</span><span class="p">,</span>
                           <span class="n">array_ops</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">is_too_large</span><span class="p">,</span> <span class="n">too_large_value</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>


<span class="c1"># TODO(b/35290280): Add unit-tests.</span>
<span class="k">def</span> <span class="nf">dimension_size</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Returns the size of a specific dimension.&quot;&quot;&quot;</span>
  <span class="c1"># Since tf.gather isn&#39;t &quot;constant-in, constant-out&quot;, we must first check the</span>
  <span class="c1"># static shape or fallback to dynamic shape.</span>
  <span class="n">s</span> <span class="o">=</span> <span class="n">tensor_shape</span><span class="o">.</span><span class="n">dimension_value</span><span class="p">(</span>
      <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">with_rank_at_least</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">axis</span><span class="p">))[</span><span class="n">axis</span><span class="p">])</span>
  <span class="k">if</span> <span class="n">s</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">s</span>
  <span class="k">return</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">)[</span><span class="n">axis</span><span class="p">]</span>


<span class="k">def</span> <span class="nf">process_quadrature_grid_and_probs</span><span class="p">(</span>
    <span class="n">quadrature_grid_and_probs</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">validate_args</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Validates quadrature grid, probs or computes them as necessary.</span>

<span class="sd">  Args:</span>
<span class="sd">    quadrature_grid_and_probs: Python pair of `float`-like `Tensor`s</span>
<span class="sd">      representing the sample points and the corresponding (possibly</span>
<span class="sd">      normalized) weight.  When `None`, defaults to:</span>
<span class="sd">      `np.polynomial.hermite.hermgauss(deg=8)`.</span>
<span class="sd">    dtype: The expected `dtype` of `grid` and `probs`.</span>
<span class="sd">    validate_args: Python `bool`, default `False`. When `True` distribution</span>
<span class="sd">      parameters are checked for validity despite possibly degrading runtime</span>
<span class="sd">      performance. When `False` invalid inputs may silently render incorrect</span>
<span class="sd">      outputs.</span>
<span class="sd">    name: Python `str` name prefixed to Ops created by this class.</span>

<span class="sd">  Returns:</span>
<span class="sd">     quadrature_grid_and_probs: Python pair of `float`-like `Tensor`s</span>
<span class="sd">      representing the sample points and the corresponding (possibly</span>
<span class="sd">      normalized) weight.</span>

<span class="sd">  Raises:</span>
<span class="sd">    ValueError: if `quadrature_grid_and_probs is not None` and</span>
<span class="sd">      `len(quadrature_grid_and_probs[0]) != len(quadrature_grid_and_probs[1])`</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">with</span> <span class="n">ops</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s2">&quot;process_quadrature_grid_and_probs&quot;</span><span class="p">,</span>
                      <span class="p">[</span><span class="n">quadrature_grid_and_probs</span><span class="p">]):</span>
    <span class="k">if</span> <span class="n">quadrature_grid_and_probs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">grid</span><span class="p">,</span> <span class="n">probs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">polynomial</span><span class="o">.</span><span class="n">hermite</span><span class="o">.</span><span class="n">hermgauss</span><span class="p">(</span><span class="n">deg</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
      <span class="n">grid</span> <span class="o">=</span> <span class="n">grid</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="o">.</span><span class="n">as_numpy_dtype</span><span class="p">)</span>
      <span class="n">probs</span> <span class="o">=</span> <span class="n">probs</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="o">.</span><span class="n">as_numpy_dtype</span><span class="p">)</span>
      <span class="n">probs</span> <span class="o">/=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">probs</span><span class="p">,</span> <span class="nb">ord</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
      <span class="n">grid</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;grid&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
      <span class="n">probs</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">probs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;probs&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">grid</span><span class="p">,</span> <span class="n">probs</span>

    <span class="n">grid</span><span class="p">,</span> <span class="n">probs</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">quadrature_grid_and_probs</span><span class="p">)</span>
    <span class="n">grid</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;grid&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">probs</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">probs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;unnormalized_probs&quot;</span><span class="p">,</span>
                                  <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">probs</span> <span class="o">/=</span> <span class="n">linalg_ops</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">probs</span><span class="p">,</span> <span class="nb">ord</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;probs&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_static_event_size</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
      <span class="sd">&quot;&quot;&quot;Returns the static size of a specific dimension or `None`.&quot;&quot;&quot;</span>
      <span class="k">return</span> <span class="n">tensor_shape</span><span class="o">.</span><span class="n">dimension_value</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">with_rank_at_least</span><span class="p">(</span><span class="mi">1</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

    <span class="n">m</span><span class="p">,</span> <span class="n">n</span> <span class="o">=</span> <span class="n">_static_event_size</span><span class="p">(</span><span class="n">probs</span><span class="p">),</span> <span class="n">_static_event_size</span><span class="p">(</span><span class="n">grid</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">m</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">n</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">if</span> <span class="n">m</span> <span class="o">!=</span> <span class="n">n</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;`quadrature_grid_and_probs` must be a `tuple` of &quot;</span>
                         <span class="s2">&quot;same-length zero-th-dimension `Tensor`s &quot;</span>
                         <span class="s2">&quot;(saw lengths </span><span class="si">{}</span><span class="s2">, </span><span class="si">{}</span><span class="s2">)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>
    <span class="k">elif</span> <span class="n">validate_args</span><span class="p">:</span>
      <span class="n">assertions</span> <span class="o">=</span> <span class="p">[</span>
          <span class="n">check_ops</span><span class="o">.</span><span class="n">assert_equal</span><span class="p">(</span>
              <span class="n">dimension_size</span><span class="p">(</span><span class="n">probs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span>
              <span class="n">dimension_size</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span>
              <span class="n">message</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;`quadrature_grid_and_probs` must be a `tuple` of &quot;</span>
                       <span class="s2">&quot;same-length zero-th-dimension `Tensor`s&quot;</span><span class="p">)),</span>
      <span class="p">]</span>
      <span class="k">with</span> <span class="n">ops</span><span class="o">.</span><span class="n">control_dependencies</span><span class="p">(</span><span class="n">assertions</span><span class="p">):</span>
        <span class="n">grid</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">grid</span><span class="p">)</span>
        <span class="n">probs</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">probs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">grid</span><span class="p">,</span> <span class="n">probs</span>


<span class="k">def</span> <span class="nf">pad</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">front</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">back</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">count</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Pads `value` to the front and/or back of a `Tensor` dim, `count` times.</span>

<span class="sd">  Args:</span>
<span class="sd">    x: `Tensor` input.</span>
<span class="sd">    axis: Scalar `int`-like `Tensor` representing the single dimension to pad.</span>
<span class="sd">      (Negative indexing is supported.)</span>
<span class="sd">    front: Python `bool`; if `True` the beginning of the `axis` dimension is</span>
<span class="sd">      padded with `value`, `count` times. If `False` no front padding is made.</span>
<span class="sd">    back: Python `bool`; if `True` the end of the `axis` dimension is</span>
<span class="sd">      padded with `value`, `count` times. If `False` no end padding is made.</span>
<span class="sd">    value: Scalar `int`-like `Tensor` representing the actual value added to the</span>
<span class="sd">      front and/or back of the `axis` dimension of `x`.</span>
<span class="sd">    count: Scalar `int`-like `Tensor` representing number of elements added to</span>
<span class="sd">      the front and/or back of the `axis` dimension of `x`. E.g., if</span>
<span class="sd">      `front = back = True` then `2 * count` elements are added.</span>
<span class="sd">    name: Python `str` name prefixed to Ops created by this function.</span>

<span class="sd">  Returns:</span>
<span class="sd">    pad: The padded version of input `x`.</span>

<span class="sd">  Raises:</span>
<span class="sd">    ValueError: if both `front` and `back` are `False`.</span>
<span class="sd">    TypeError: if `count` is not `int`-like.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">with</span> <span class="n">ops</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s2">&quot;pad&quot;</span><span class="p">,</span> <span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">count</span><span class="p">]):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;x&quot;</span><span class="p">)</span>
    <span class="n">value</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;value&quot;</span><span class="p">)</span>
    <span class="n">count</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">count</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;count&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">count</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">is_integer</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;`count.dtype` (`</span><span class="si">{}</span><span class="s2">`) must be `int`-like.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
          <span class="n">count</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">name</span><span class="p">))</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">front</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">back</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;At least one of `front`, `back` must be `True`.&quot;</span><span class="p">)</span>
    <span class="n">ndims</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">ndims</span> <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">ndims</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
             <span class="k">else</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">rank</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;ndims&quot;</span><span class="p">))</span>
    <span class="n">axis</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;axis&quot;</span><span class="p">)</span>
    <span class="n">axis_</span> <span class="o">=</span> <span class="n">tensor_util</span><span class="o">.</span><span class="n">constant_value</span><span class="p">(</span><span class="n">axis</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">axis_</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">axis</span> <span class="o">=</span> <span class="n">axis_</span>
      <span class="k">if</span> <span class="n">axis</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">axis</span> <span class="o">=</span> <span class="n">ndims</span> <span class="o">+</span> <span class="n">axis</span>
      <span class="n">count_</span> <span class="o">=</span> <span class="n">tensor_util</span><span class="o">.</span><span class="n">constant_value</span><span class="p">(</span><span class="n">count</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">axis_</span> <span class="o">&gt;=</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">ndims</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">head</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="n">axis</span><span class="p">]</span>
        <span class="n">middle</span> <span class="o">=</span> <span class="n">tensor_shape</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">(</span>
            <span class="kc">None</span> <span class="k">if</span> <span class="n">count_</span> <span class="ow">is</span> <span class="kc">None</span>
            <span class="k">else</span> <span class="p">(</span><span class="n">tensor_shape</span><span class="o">.</span><span class="n">dimension_at_index</span><span class="p">(</span>
                <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span> <span class="o">+</span> <span class="n">count_</span> <span class="o">*</span> <span class="p">(</span><span class="n">front</span> <span class="o">+</span> <span class="n">back</span><span class="p">)))</span>
        <span class="n">tail</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">axis</span><span class="o">+</span><span class="mi">1</span><span class="p">:]</span>
        <span class="n">final_shape</span> <span class="o">=</span> <span class="n">head</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">middle</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">tail</span><span class="p">))</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">final_shape</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">axis</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">axis</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">ndims</span> <span class="o">+</span> <span class="n">axis</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span>
      <span class="n">final_shape</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span>
        <span class="n">x</span><span class="p">,</span>
        <span class="n">paddings</span><span class="o">=</span><span class="n">array_ops</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span>
            <span class="n">indices</span><span class="o">=</span><span class="n">array_ops</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">axis</span> <span class="k">if</span> <span class="n">front</span> <span class="k">else</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
                                     <span class="n">axis</span> <span class="k">if</span> <span class="n">back</span> <span class="k">else</span> <span class="o">-</span><span class="mi">1</span><span class="p">]),</span>
            <span class="n">depth</span><span class="o">=</span><span class="n">ndims</span><span class="p">,</span>
            <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
            <span class="n">on_value</span><span class="o">=</span><span class="n">count</span><span class="p">,</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span>
        <span class="n">constant_values</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">final_shape</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">x</span><span class="o">.</span><span class="n">set_shape</span><span class="p">(</span><span class="n">final_shape</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span>


<span class="k">def</span> <span class="nf">parent_frame_arguments</span><span class="p">():</span>
  <span class="sd">&quot;&quot;&quot;Returns parent frame arguments.</span>

<span class="sd">  When called inside a function, returns a dictionary with the caller&#39;s function</span>
<span class="sd">  arguments. These are positional arguments and keyword arguments (**kwargs),</span>
<span class="sd">  while variable arguments (*varargs) are excluded.</span>

<span class="sd">  When called at global scope, this will return an empty dictionary, since there</span>
<span class="sd">  are no arguments.</span>

<span class="sd">  WARNING: If caller function argument names are overloaded before invoking</span>
<span class="sd">  this method, then values will reflect the overloaded value. For this reason,</span>
<span class="sd">  we recommend calling `parent_frame_arguments` at the beginning of the</span>
<span class="sd">  function.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="c1"># All arguments and the names used for *varargs, and **kwargs</span>
  <span class="n">arg_names</span><span class="p">,</span> <span class="n">variable_arg_name</span><span class="p">,</span> <span class="n">keyword_arg_name</span><span class="p">,</span> <span class="n">local_vars</span> <span class="o">=</span> <span class="p">(</span>
      <span class="n">tf_inspect</span><span class="o">.</span><span class="n">_inspect</span><span class="o">.</span><span class="n">getargvalues</span><span class="p">(</span>  <span class="c1"># pylint: disable=protected-access</span>
          <span class="c1"># Get the first frame of the caller of this method.</span>
          <span class="n">tf_inspect</span><span class="o">.</span><span class="n">_inspect</span><span class="o">.</span><span class="n">stack</span><span class="p">()[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]))</span>  <span class="c1"># pylint: disable=protected-access</span>

  <span class="c1"># Remove the *varargs, and flatten the **kwargs. Both are</span>
  <span class="c1"># nested lists.</span>
  <span class="n">local_vars</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">variable_arg_name</span><span class="p">,</span> <span class="p">{})</span>
  <span class="n">keyword_args</span> <span class="o">=</span> <span class="n">local_vars</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">keyword_arg_name</span><span class="p">,</span> <span class="p">{})</span>

  <span class="n">final_args</span> <span class="o">=</span> <span class="p">{}</span>
  <span class="c1"># Copy over arguments and their values. In general, local_vars</span>
  <span class="c1"># may contain more than just the arguments, since this method</span>
  <span class="c1"># can be called anywhere in a function.</span>
  <span class="k">for</span> <span class="n">arg_name</span> <span class="ow">in</span> <span class="n">arg_names</span><span class="p">:</span>
    <span class="n">final_args</span><span class="p">[</span><span class="n">arg_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">local_vars</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">arg_name</span><span class="p">)</span>
  <span class="n">final_args</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">keyword_args</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">final_args</span>


<div class="viewcode-block" id="AppendDocstring"><a class="viewcode-back" href="../../../../../zfit.util.html#zfit.util.AppendDocstring">[docs]</a><span class="k">class</span> <span class="nc">AppendDocstring</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Helper class to promote private subclass docstring to public counterpart.</span>

<span class="sd">  Example:</span>

<span class="sd">  ```python</span>
<span class="sd">  class TransformedDistribution(Distribution):</span>
<span class="sd">    @distribution_util.AppendDocstring(</span>
<span class="sd">      additional_note=&quot;A special note!&quot;,</span>
<span class="sd">      kwargs_dict={&quot;foo&quot;: &quot;An extra arg.&quot;})</span>
<span class="sd">    def _prob(self, y, foo=None):</span>
<span class="sd">      pass</span>
<span class="sd">  ```</span>

<span class="sd">  In this case, the `AppendDocstring` decorator appends the `additional_note` to</span>
<span class="sd">  the docstring of `prob` (not `_prob`) and adds a new `kwargs`</span>
<span class="sd">  section with each dictionary item as a bullet-point.</span>

<span class="sd">  For a more detailed example, see `TransformedDistribution`.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">additional_note</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">kwargs_dict</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Initializes the AppendDocstring object.</span>

<span class="sd">    Args:</span>
<span class="sd">      additional_note: Python string added as additional docstring to public</span>
<span class="sd">        version of function.</span>
<span class="sd">      kwargs_dict: Python string/string dictionary representing</span>
<span class="sd">        specific kwargs expanded from the **kwargs input.</span>

<span class="sd">    Raises:</span>
<span class="sd">      ValueError: if kwargs_dict.key contains whitespace.</span>
<span class="sd">      ValueError: if kwargs_dict.value contains newlines.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_additional_note</span> <span class="o">=</span> <span class="n">additional_note</span>
    <span class="k">if</span> <span class="n">kwargs_dict</span><span class="p">:</span>
      <span class="n">bullets</span> <span class="o">=</span> <span class="p">[]</span>
      <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">kwargs_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">()):</span>
        <span class="n">value</span> <span class="o">=</span> <span class="n">kwargs_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
        <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">isspace</span><span class="p">()</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">key</span><span class="p">):</span>
          <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
              <span class="s2">&quot;Parameter name </span><span class="se">\&quot;</span><span class="si">%s</span><span class="se">\&quot;</span><span class="s2"> contains whitespace.&quot;</span> <span class="o">%</span> <span class="n">key</span><span class="p">)</span>
        <span class="n">value</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">lstrip</span><span class="p">()</span>
        <span class="k">if</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="ow">in</span> <span class="n">value</span><span class="p">:</span>
          <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
              <span class="s2">&quot;Parameter description for </span><span class="se">\&quot;</span><span class="si">%s</span><span class="se">\&quot;</span><span class="s2"> contains newlines.&quot;</span> <span class="o">%</span> <span class="n">key</span><span class="p">)</span>
        <span class="n">bullets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;*  `</span><span class="si">%s</span><span class="s2">`: </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">))</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_additional_note</span> <span class="o">+=</span> <span class="p">(</span><span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2">##### `kwargs`:</span><span class="se">\n\n</span><span class="s2">&quot;</span> <span class="o">+</span>
                                <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">bullets</span><span class="p">))</span>

  <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fn</span><span class="p">):</span>
    <span class="nd">@functools</span><span class="o">.</span><span class="n">wraps</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">_fn</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
      <span class="k">return</span> <span class="n">fn</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">_fn</span><span class="o">.</span><span class="vm">__doc__</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">_fn</span><span class="o">.</span><span class="vm">__doc__</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_additional_note</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">_fn</span><span class="o">.</span><span class="vm">__doc__</span> <span class="o">+=</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">_additional_note</span>
    <span class="k">return</span> <span class="n">_fn</span></div>
</pre></div>

           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, zfit

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>