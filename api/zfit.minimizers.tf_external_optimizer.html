<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
  <head>
    <meta charset="utf-8" />
    <title>tf_external_optimizer &#8212; zfit 0.1.dev139+g3358391 documentation</title>
    <link rel="stylesheet" href="../_static/bootstrap-sphinx.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="../_static/language_data.js"></script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="models" href="zfit.models.html" />
    <link rel="prev" title="optimizers_tf" href="zfit.minimizers.optimizers_tf.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">
<script type="text/javascript" src="../_static/js/jquery-1.11.0.min.js "></script>
<script type="text/javascript" src="../_static/js/jquery-fix.js "></script>
<script type="text/javascript" src="../_static/bootstrap-2.3.2/js/bootstrap.min.js "></script>
<script type="text/javascript" src="../_static/bootstrap-sphinx.js "></script>

  </head><body>

  <div id="navbar" class="navbar navbar-fixed-top">
    <div class="navbar-inner">
      <div class="container">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>

        <a class="brand" href="../index.html">
          zfit</a>
        <span class="navbar-text pull-left"><b>0.1.dev139+g3358391</b></span>

        <div class="nav-collapse">
          <ul class="nav">
            <li class="divider-vertical"></li>
            
                <li><a href="../getting_started.html">Getting started</a></li>
                <li><a href="../space.html">Space</a></li>
                <li><a href="../parameter.html">Parameter</a></li>
                <li><a href="../model.html">Model</a></li>
                <li><a href="../data.html">Data</a></li>
                <li><a href="../loss.html">Loss</a></li>
                <li><a href="../minimize.html">Minimize</a></li>
                <li><a href="../API.html">API</a></li>
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="../index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><ul>
<li class="toctree-l1"><a class="reference internal" href="../getting_started.html">Getting started with zfit</a></li>
<li class="toctree-l1"><a class="reference internal" href="../downloading.html">Downloading and Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contributing.html">Contributing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../space.html">Space, Observable and Range</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parameter.html">Parameter</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model.html">Building a model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../data.html">Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../loss.html">Loss</a></li>
<li class="toctree-l1"><a class="reference internal" href="../minimize.html">Minimization</a></li>
</ul>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../API.html">zfit API documentation</a></li>
</ul>
</ul>
</li>
              
            
            
            
            
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="../search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
      </div>
    </div>
  </div>

<div class="container">
  <div class="row">
    <div class="body span12 content" role="main">
      
  <div class="section" id="module-zfit.minimizers.tf_external_optimizer">
<span id="tf-external-optimizer"></span><h1>tf_external_optimizer<a class="headerlink" href="#module-zfit.minimizers.tf_external_optimizer" title="Permalink to this headline">¶</a></h1>
<p>TensorFlow interface for third-party optimizers.</p>
<dl class="class">
<dt id="zfit.minimizers.tf_external_optimizer.ExternalOptimizerInterface">
<em class="property">class </em><code class="sig-prename descclassname">zfit.minimizers.tf_external_optimizer.</code><code class="sig-name descname">ExternalOptimizerInterface</code><span class="sig-paren">(</span><em class="sig-param">loss</em>, <em class="sig-param">var_list=None</em>, <em class="sig-param">equalities=None</em>, <em class="sig-param">inequalities=None</em>, <em class="sig-param">var_to_bounds=None</em>, <em class="sig-param">**optimizer_kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/zfit/minimizers/tf_external_optimizer.html#ExternalOptimizerInterface"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#zfit.minimizers.tf_external_optimizer.ExternalOptimizerInterface" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>Base class for interfaces with external optimization algorithms.</p>
<p>Subclass this and implement <cite>_minimize</cite> in order to wrap a new optimization
algorithm.</p>
<p><cite>ExternalOptimizerInterface</cite> should not be instantiated directly; instead use
e.g. <cite>ScipyOptimizerInterface</cite>.</p>
<p>Initialize a new interface instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>loss</strong> – A scalar <cite>Tensor</cite> to be minimized.</p></li>
<li><p><strong>var_list</strong> – Optional <cite>list</cite> of <cite>Variable</cite> objects to update to minimize
<cite>loss</cite>.  Defaults to the list of variables collected in the graph
under the key <cite>GraphKeys.TRAINABLE_VARIABLES</cite>.</p></li>
<li><p><strong>equalities</strong> – Optional <cite>list</cite> of equality constraint scalar <a href="#id1"><span class="problematic" id="id2">`</span></a>Tensor`s to be
held equal to zero.</p></li>
<li><p><strong>inequalities</strong> – Optional <cite>list</cite> of inequality constraint scalar <a href="#id3"><span class="problematic" id="id4">`</span></a>Tensor`s
to be held nonnegative.</p></li>
<li><p><strong>var_to_bounds</strong> – <p>Optional <cite>dict</cite> where each key is an optimization
<cite>Variable</cite> and each corresponding value is a length-2 tuple of
<cite>(low, high)</cite> bounds. Although enforcing this kind of simple constraint
could be accomplished with the <cite>inequalities</cite> arg, not all optimization
algorithms support general inequality constraints, e.g. L-BFGS-B. Both
<cite>low</cite> and <cite>high</cite> can either be numbers or anything convertible to a
NumPy array that can be broadcast to the shape of <cite>var</cite> (using
<cite>np.broadcast_to</cite>). To indicate that there is no bound, use <cite>None</cite> (or
<cite>+/- np.infty</cite>). For example, if <cite>var</cite> is a 2x3 matrix, then any of
the following corresponding <cite>bounds</cite> could be supplied:
* <cite>(0, np.infty)</cite>: Each element of <cite>var</cite> held positive.
* <cite>(-np.infty, [1, 2])</cite>: First column less than 1, second column less</p>
<blockquote>
<div><p>than 2.</p>
</div></blockquote>
<ul>
<li><p><cite>(-np.infty, [[1], [2], [3]])</cite>: First row less than 1, second row less
than 2, etc.</p></li>
<li><p><cite>(-np.infty, [[1, 2, 3], [4, 5, 6]])</cite>: Entry <cite>var[0, 0]</cite> less than 1,
<cite>var[0, 1]</cite> less than 2, etc.</p></li>
</ul>
</p></li>
<li><p><strong>**optimizer_kwargs</strong> – Other subclass-specific keyword arguments.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="zfit.minimizers.tf_external_optimizer.ExternalOptimizerInterface.minimize">
<code class="sig-name descname">minimize</code><span class="sig-paren">(</span><em class="sig-param">session=None</em>, <em class="sig-param">feed_dict=None</em>, <em class="sig-param">fetches=None</em>, <em class="sig-param">step_callback=None</em>, <em class="sig-param">loss_callback=None</em>, <em class="sig-param">**run_kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/zfit/minimizers/tf_external_optimizer.html#ExternalOptimizerInterface.minimize"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#zfit.minimizers.tf_external_optimizer.ExternalOptimizerInterface.minimize" title="Permalink to this definition">¶</a></dt>
<dd><p>Minimize a scalar <cite>Tensor</cite>.</p>
<p>Variables subject to optimization are updated in-place at the end of
optimization.</p>
<p>Note that this method does <em>not</em> just return a minimization <cite>Op</cite>, unlike
<cite>Optimizer.minimize()</cite>; instead it actually performs minimization by
executing commands to control a <cite>Session</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>session</strong> – A <cite>Session</cite> instance.</p></li>
<li><p><strong>feed_dict</strong> – A feed dict to be passed to calls to <cite>session.run</cite>.</p></li>
<li><p><strong>fetches</strong> – A list of <cite>Tensor`s to fetch and supply to `loss_callback</cite>
as positional arguments.</p></li>
<li><p><strong>step_callback</strong> – A function to be called at each optimization step;
arguments are the current values of all optimization variables
flattened into a single vector.</p></li>
<li><p><strong>loss_callback</strong> – A function to be called every time the loss and gradients
are computed, with evaluated fetches supplied as positional arguments.</p></li>
<li><p><strong>**run_kwargs</strong> – kwargs to pass to <cite>session.run</cite>.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="zfit.minimizers.tf_external_optimizer.ScipyOptimizerInterface">
<em class="property">class </em><code class="sig-prename descclassname">zfit.minimizers.tf_external_optimizer.</code><code class="sig-name descname">ScipyOptimizerInterface</code><span class="sig-paren">(</span><em class="sig-param">loss</em>, <em class="sig-param">var_list=None</em>, <em class="sig-param">equalities=None</em>, <em class="sig-param">inequalities=None</em>, <em class="sig-param">var_to_bounds=None</em>, <em class="sig-param">**optimizer_kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/zfit/minimizers/tf_external_optimizer.html#ScipyOptimizerInterface"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#zfit.minimizers.tf_external_optimizer.ScipyOptimizerInterface" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#zfit.minimizers.tf_external_optimizer.ExternalOptimizerInterface" title="zfit.minimizers.tf_external_optimizer.ExternalOptimizerInterface"><code class="xref py py-class docutils literal notranslate"><span class="pre">zfit.minimizers.tf_external_optimizer.ExternalOptimizerInterface</span></code></a></p>
<p>Wrapper allowing <cite>scipy.optimize.minimize</cite> to operate a <cite>tf.compat.v1.Session</cite>.</p>
<p>Example:</p>
<p><a href="#id5"><span class="problematic" id="id6">``</span></a><a href="#id7"><span class="problematic" id="id8">`</span></a>python
vector = tf.Variable([7., 7.], ‘vector’)</p>
<p># Make vector norm as small as possible.
loss = tf.reduce_sum(tf.square(vector))</p>
<p>optimizer = ScipyOptimizerInterface(loss, options={‘maxiter’: 100})</p>
<dl class="simple">
<dt>with tf.compat.v1.Session() as session:</dt><dd><p>optimizer.minimize(session)</p>
</dd>
</dl>
<p># The value of vector should now be [0., 0.].
<a href="#id9"><span class="problematic" id="id10">``</span></a><a href="#id11"><span class="problematic" id="id12">`</span></a></p>
<p>Example with simple bound constraints:</p>
<p><a href="#id13"><span class="problematic" id="id14">``</span></a><a href="#id15"><span class="problematic" id="id16">`</span></a>python
vector = tf.Variable([7., 7.], ‘vector’)</p>
<p># Make vector norm as small as possible.
loss = tf.reduce_sum(tf.square(vector))</p>
<dl class="simple">
<dt>optimizer = ScipyOptimizerInterface(</dt><dd><p>loss, var_to_bounds={vector: ([1, 2], np.infty)})</p>
</dd>
<dt>with tf.compat.v1.Session() as session:</dt><dd><p>optimizer.minimize(session)</p>
</dd>
</dl>
<p># The value of vector should now be [1., 2.].
<a href="#id17"><span class="problematic" id="id18">``</span></a><a href="#id19"><span class="problematic" id="id20">`</span></a></p>
<p>Example with more complicated constraints:</p>
<p><a href="#id21"><span class="problematic" id="id22">``</span></a><a href="#id23"><span class="problematic" id="id24">`</span></a>python
vector = tf.Variable([7., 7.], ‘vector’)</p>
<p># Make vector norm as small as possible.
loss = tf.reduce_sum(tf.square(vector))
# Ensure the vector’s y component is = 1.
equalities = [vector[1] - 1.]
# Ensure the vector’s x component is &gt;= 1.
inequalities = [vector[0] - 1.]</p>
<p># Our default SciPy optimization algorithm, L-BFGS-B, does not support
# general constraints. Thus we use SLSQP instead.
optimizer = ScipyOptimizerInterface(</p>
<blockquote>
<div><p>loss, equalities=equalities, inequalities=inequalities, method=’SLSQP’)</p>
</div></blockquote>
<dl class="simple">
<dt>with tf.compat.v1.Session() as session:</dt><dd><p>optimizer.minimize(session)</p>
</dd>
</dl>
<p># The value of vector should now be [1., 1.].
<a href="#id25"><span class="problematic" id="id26">``</span></a><a href="#id27"><span class="problematic" id="id28">`</span></a></p>
<p>Initialize a new interface instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>loss</strong> – A scalar <cite>Tensor</cite> to be minimized.</p></li>
<li><p><strong>var_list</strong> – Optional <cite>list</cite> of <cite>Variable</cite> objects to update to minimize
<cite>loss</cite>.  Defaults to the list of variables collected in the graph
under the key <cite>GraphKeys.TRAINABLE_VARIABLES</cite>.</p></li>
<li><p><strong>equalities</strong> – Optional <cite>list</cite> of equality constraint scalar <a href="#id29"><span class="problematic" id="id30">`</span></a>Tensor`s to be
held equal to zero.</p></li>
<li><p><strong>inequalities</strong> – Optional <cite>list</cite> of inequality constraint scalar <a href="#id31"><span class="problematic" id="id32">`</span></a>Tensor`s
to be held nonnegative.</p></li>
<li><p><strong>var_to_bounds</strong> – <p>Optional <cite>dict</cite> where each key is an optimization
<cite>Variable</cite> and each corresponding value is a length-2 tuple of
<cite>(low, high)</cite> bounds. Although enforcing this kind of simple constraint
could be accomplished with the <cite>inequalities</cite> arg, not all optimization
algorithms support general inequality constraints, e.g. L-BFGS-B. Both
<cite>low</cite> and <cite>high</cite> can either be numbers or anything convertible to a
NumPy array that can be broadcast to the shape of <cite>var</cite> (using
<cite>np.broadcast_to</cite>). To indicate that there is no bound, use <cite>None</cite> (or
<cite>+/- np.infty</cite>). For example, if <cite>var</cite> is a 2x3 matrix, then any of
the following corresponding <cite>bounds</cite> could be supplied:
* <cite>(0, np.infty)</cite>: Each element of <cite>var</cite> held positive.
* <cite>(-np.infty, [1, 2])</cite>: First column less than 1, second column less</p>
<blockquote>
<div><p>than 2.</p>
</div></blockquote>
<ul>
<li><p><cite>(-np.infty, [[1], [2], [3]])</cite>: First row less than 1, second row less
than 2, etc.</p></li>
<li><p><cite>(-np.infty, [[1, 2, 3], [4, 5, 6]])</cite>: Entry <cite>var[0, 0]</cite> less than 1,
<cite>var[0, 1]</cite> less than 2, etc.</p></li>
</ul>
</p></li>
<li><p><strong>**optimizer_kwargs</strong> – Other subclass-specific keyword arguments.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="zfit.minimizers.tf_external_optimizer.ScipyOptimizerInterface.minimize">
<code class="sig-name descname">minimize</code><span class="sig-paren">(</span><em class="sig-param">session=None</em>, <em class="sig-param">feed_dict=None</em>, <em class="sig-param">fetches=None</em>, <em class="sig-param">step_callback=None</em>, <em class="sig-param">loss_callback=None</em>, <em class="sig-param">**run_kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#zfit.minimizers.tf_external_optimizer.ScipyOptimizerInterface.minimize" title="Permalink to this definition">¶</a></dt>
<dd><p>Minimize a scalar <cite>Tensor</cite>.</p>
<p>Variables subject to optimization are updated in-place at the end of
optimization.</p>
<p>Note that this method does <em>not</em> just return a minimization <cite>Op</cite>, unlike
<cite>Optimizer.minimize()</cite>; instead it actually performs minimization by
executing commands to control a <cite>Session</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>session</strong> – A <cite>Session</cite> instance.</p></li>
<li><p><strong>feed_dict</strong> – A feed dict to be passed to calls to <cite>session.run</cite>.</p></li>
<li><p><strong>fetches</strong> – A list of <cite>Tensor`s to fetch and supply to `loss_callback</cite>
as positional arguments.</p></li>
<li><p><strong>step_callback</strong> – A function to be called at each optimization step;
arguments are the current values of all optimization variables
flattened into a single vector.</p></li>
<li><p><strong>loss_callback</strong> – A function to be called every time the loss and gradients
are computed, with evaluated fetches supplied as positional arguments.</p></li>
<li><p><strong>**run_kwargs</strong> – kwargs to pass to <cite>session.run</cite>.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>


    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
    </p>
    <p>
        &copy; Copyright Copyright 2018, zfit.<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 2.2.1.<br/>
    </p>
  </div>
</footer>
  </body>
</html>